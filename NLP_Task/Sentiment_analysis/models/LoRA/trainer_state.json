{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.997586484312148,
  "eval_steps": 50,
  "global_step": 620,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006436041834271922,
      "grad_norm": 1.9685649871826172,
      "learning_rate": 3.2258064516129035e-07,
      "loss": 1.4541,
      "step": 1
    },
    {
      "epoch": 0.012872083668543845,
      "grad_norm": 1.8912683725357056,
      "learning_rate": 6.451612903225807e-07,
      "loss": 1.4139,
      "step": 2
    },
    {
      "epoch": 0.019308125502815767,
      "grad_norm": 1.9528506994247437,
      "learning_rate": 9.67741935483871e-07,
      "loss": 1.4281,
      "step": 3
    },
    {
      "epoch": 0.02574416733708769,
      "grad_norm": 1.9975438117980957,
      "learning_rate": 1.2903225806451614e-06,
      "loss": 1.4522,
      "step": 4
    },
    {
      "epoch": 0.032180209171359615,
      "grad_norm": 1.9404792785644531,
      "learning_rate": 1.6129032258064516e-06,
      "loss": 1.4513,
      "step": 5
    },
    {
      "epoch": 0.038616251005631534,
      "grad_norm": 1.8073220252990723,
      "learning_rate": 1.935483870967742e-06,
      "loss": 1.8826,
      "step": 6
    },
    {
      "epoch": 0.04505229283990346,
      "grad_norm": 1.90586256980896,
      "learning_rate": 2.2580645161290324e-06,
      "loss": 1.42,
      "step": 7
    },
    {
      "epoch": 0.05148833467417538,
      "grad_norm": 1.8590991497039795,
      "learning_rate": 2.580645161290323e-06,
      "loss": 1.4164,
      "step": 8
    },
    {
      "epoch": 0.057924376508447305,
      "grad_norm": 1.9264955520629883,
      "learning_rate": 2.903225806451613e-06,
      "loss": 1.429,
      "step": 9
    },
    {
      "epoch": 0.06436041834271923,
      "grad_norm": 1.8172402381896973,
      "learning_rate": 3.225806451612903e-06,
      "loss": 2.2137,
      "step": 10
    },
    {
      "epoch": 0.07079646017699115,
      "grad_norm": 1.9768317937850952,
      "learning_rate": 3.548387096774194e-06,
      "loss": 1.4438,
      "step": 11
    },
    {
      "epoch": 0.07723250201126307,
      "grad_norm": 1.943060040473938,
      "learning_rate": 3.870967741935484e-06,
      "loss": 1.8471,
      "step": 12
    },
    {
      "epoch": 0.083668543845535,
      "grad_norm": 1.972120761871338,
      "learning_rate": 4.193548387096774e-06,
      "loss": 1.4135,
      "step": 13
    },
    {
      "epoch": 0.09010458567980692,
      "grad_norm": 2.0409796237945557,
      "learning_rate": 4.516129032258065e-06,
      "loss": 1.4412,
      "step": 14
    },
    {
      "epoch": 0.09654062751407884,
      "grad_norm": 1.98094642162323,
      "learning_rate": 4.838709677419355e-06,
      "loss": 1.8586,
      "step": 15
    },
    {
      "epoch": 0.10297666934835076,
      "grad_norm": 2.0509204864501953,
      "learning_rate": 5.161290322580646e-06,
      "loss": 1.4175,
      "step": 16
    },
    {
      "epoch": 0.10941271118262269,
      "grad_norm": 1.9887115955352783,
      "learning_rate": 5.483870967741935e-06,
      "loss": 1.7649,
      "step": 17
    },
    {
      "epoch": 0.11584875301689461,
      "grad_norm": 2.0948925018310547,
      "learning_rate": 5.806451612903226e-06,
      "loss": 1.4001,
      "step": 18
    },
    {
      "epoch": 0.12228479485116653,
      "grad_norm": 2.1560323238372803,
      "learning_rate": 6.129032258064517e-06,
      "loss": 1.8284,
      "step": 19
    },
    {
      "epoch": 0.12872083668543846,
      "grad_norm": 2.206878900527954,
      "learning_rate": 6.451612903225806e-06,
      "loss": 1.3923,
      "step": 20
    },
    {
      "epoch": 0.13515687851971037,
      "grad_norm": 2.2437219619750977,
      "learning_rate": 6.774193548387097e-06,
      "loss": 1.3814,
      "step": 21
    },
    {
      "epoch": 0.1415929203539823,
      "grad_norm": 2.230372190475464,
      "learning_rate": 7.096774193548388e-06,
      "loss": 1.7578,
      "step": 22
    },
    {
      "epoch": 0.14802896218825423,
      "grad_norm": 2.3423988819122314,
      "learning_rate": 7.4193548387096784e-06,
      "loss": 1.765,
      "step": 23
    },
    {
      "epoch": 0.15446500402252614,
      "grad_norm": 2.3612494468688965,
      "learning_rate": 7.741935483870968e-06,
      "loss": 1.6984,
      "step": 24
    },
    {
      "epoch": 0.16090104585679807,
      "grad_norm": 2.4585764408111572,
      "learning_rate": 8.064516129032258e-06,
      "loss": 1.3147,
      "step": 25
    },
    {
      "epoch": 0.16733708769107,
      "grad_norm": 2.6449835300445557,
      "learning_rate": 8.387096774193549e-06,
      "loss": 1.6698,
      "step": 26
    },
    {
      "epoch": 0.1737731295253419,
      "grad_norm": 2.557314157485962,
      "learning_rate": 8.70967741935484e-06,
      "loss": 2.0535,
      "step": 27
    },
    {
      "epoch": 0.18020917135961384,
      "grad_norm": 2.8252410888671875,
      "learning_rate": 9.03225806451613e-06,
      "loss": 1.2782,
      "step": 28
    },
    {
      "epoch": 0.18664521319388577,
      "grad_norm": 2.714287519454956,
      "learning_rate": 9.35483870967742e-06,
      "loss": 1.2228,
      "step": 29
    },
    {
      "epoch": 0.19308125502815768,
      "grad_norm": 2.7313289642333984,
      "learning_rate": 9.67741935483871e-06,
      "loss": 1.1891,
      "step": 30
    },
    {
      "epoch": 0.1995172968624296,
      "grad_norm": 2.5705578327178955,
      "learning_rate": 1e-05,
      "loss": 1.1406,
      "step": 31
    },
    {
      "epoch": 0.20595333869670152,
      "grad_norm": 2.4597842693328857,
      "learning_rate": 1.0322580645161291e-05,
      "loss": 1.5113,
      "step": 32
    },
    {
      "epoch": 0.21238938053097345,
      "grad_norm": 2.5823276042938232,
      "learning_rate": 1.0645161290322582e-05,
      "loss": 1.083,
      "step": 33
    },
    {
      "epoch": 0.21882542236524538,
      "grad_norm": 2.7782142162323,
      "learning_rate": 1.096774193548387e-05,
      "loss": 1.0326,
      "step": 34
    },
    {
      "epoch": 0.2252614641995173,
      "grad_norm": 2.9799752235412598,
      "learning_rate": 1.1290322580645164e-05,
      "loss": 1.3386,
      "step": 35
    },
    {
      "epoch": 0.23169750603378922,
      "grad_norm": 3.287259578704834,
      "learning_rate": 1.1612903225806453e-05,
      "loss": 1.7219,
      "step": 36
    },
    {
      "epoch": 0.23813354786806115,
      "grad_norm": 3.8386166095733643,
      "learning_rate": 1.1935483870967743e-05,
      "loss": 0.8593,
      "step": 37
    },
    {
      "epoch": 0.24456958970233306,
      "grad_norm": 4.304828643798828,
      "learning_rate": 1.2258064516129034e-05,
      "loss": 0.7957,
      "step": 38
    },
    {
      "epoch": 0.251005631536605,
      "grad_norm": 4.754805088043213,
      "learning_rate": 1.2580645161290324e-05,
      "loss": 1.1094,
      "step": 39
    },
    {
      "epoch": 0.2574416733708769,
      "grad_norm": 5.5707573890686035,
      "learning_rate": 1.2903225806451613e-05,
      "loss": 0.5867,
      "step": 40
    },
    {
      "epoch": 0.26387771520514886,
      "grad_norm": 5.830399990081787,
      "learning_rate": 1.3225806451612903e-05,
      "loss": 0.864,
      "step": 41
    },
    {
      "epoch": 0.27031375703942073,
      "grad_norm": 5.782106876373291,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.334,
      "step": 42
    },
    {
      "epoch": 0.27674979887369267,
      "grad_norm": 4.35565185546875,
      "learning_rate": 1.3870967741935486e-05,
      "loss": 0.2131,
      "step": 43
    },
    {
      "epoch": 0.2831858407079646,
      "grad_norm": 2.4657225608825684,
      "learning_rate": 1.4193548387096776e-05,
      "loss": 0.5132,
      "step": 44
    },
    {
      "epoch": 0.28962188254223653,
      "grad_norm": 1.3509105443954468,
      "learning_rate": 1.4516129032258066e-05,
      "loss": 0.1012,
      "step": 45
    },
    {
      "epoch": 0.29605792437650846,
      "grad_norm": 0.86557537317276,
      "learning_rate": 1.4838709677419357e-05,
      "loss": 0.0535,
      "step": 46
    },
    {
      "epoch": 0.3024939662107804,
      "grad_norm": 0.6041260361671448,
      "learning_rate": 1.5161290322580646e-05,
      "loss": 0.0502,
      "step": 47
    },
    {
      "epoch": 0.3089300080450523,
      "grad_norm": 0.5686450004577637,
      "learning_rate": 1.5483870967741936e-05,
      "loss": 0.4495,
      "step": 48
    },
    {
      "epoch": 0.3153660498793242,
      "grad_norm": 0.29662030935287476,
      "learning_rate": 1.5806451612903226e-05,
      "loss": 0.0385,
      "step": 49
    },
    {
      "epoch": 0.32180209171359614,
      "grad_norm": 0.48639413714408875,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 0.0488,
      "step": 50
    },
    {
      "epoch": 0.32180209171359614,
      "eval_loss": 0.18279580771923065,
      "eval_runtime": 51.3797,
      "eval_samples_per_second": 24.192,
      "eval_steps_per_second": 1.518,
      "step": 50
    },
    {
      "epoch": 0.32823813354786807,
      "grad_norm": 0.30760398507118225,
      "learning_rate": 1.6451612903225807e-05,
      "loss": 0.5028,
      "step": 51
    },
    {
      "epoch": 0.33467417538214,
      "grad_norm": 0.3390811085700989,
      "learning_rate": 1.6774193548387098e-05,
      "loss": 0.4489,
      "step": 52
    },
    {
      "epoch": 0.3411102172164119,
      "grad_norm": 0.3119659721851349,
      "learning_rate": 1.7096774193548388e-05,
      "loss": 0.0302,
      "step": 53
    },
    {
      "epoch": 0.3475462590506838,
      "grad_norm": 0.22402791678905487,
      "learning_rate": 1.741935483870968e-05,
      "loss": 0.0256,
      "step": 54
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 0.2646830976009369,
      "learning_rate": 1.774193548387097e-05,
      "loss": 0.0362,
      "step": 55
    },
    {
      "epoch": 0.3604183427192277,
      "grad_norm": 0.23756705224514008,
      "learning_rate": 1.806451612903226e-05,
      "loss": 0.0381,
      "step": 56
    },
    {
      "epoch": 0.3668543845534996,
      "grad_norm": 0.2306307852268219,
      "learning_rate": 1.838709677419355e-05,
      "loss": 0.0298,
      "step": 57
    },
    {
      "epoch": 0.37329042638777155,
      "grad_norm": 0.47934600710868835,
      "learning_rate": 1.870967741935484e-05,
      "loss": 0.0244,
      "step": 58
    },
    {
      "epoch": 0.3797264682220434,
      "grad_norm": 0.28406909108161926,
      "learning_rate": 1.903225806451613e-05,
      "loss": 0.3482,
      "step": 59
    },
    {
      "epoch": 0.38616251005631536,
      "grad_norm": 0.4377634525299072,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.0371,
      "step": 60
    },
    {
      "epoch": 0.3925985518905873,
      "grad_norm": 0.5158991813659668,
      "learning_rate": 1.967741935483871e-05,
      "loss": 0.0237,
      "step": 61
    },
    {
      "epoch": 0.3990345937248592,
      "grad_norm": 0.3448415994644165,
      "learning_rate": 2e-05,
      "loss": 0.4934,
      "step": 62
    },
    {
      "epoch": 0.40547063555913115,
      "grad_norm": 0.2882729768753052,
      "learning_rate": 1.9964157706093194e-05,
      "loss": 0.0089,
      "step": 63
    },
    {
      "epoch": 0.41190667739340303,
      "grad_norm": 0.13260211050510406,
      "learning_rate": 1.992831541218638e-05,
      "loss": 0.0159,
      "step": 64
    },
    {
      "epoch": 0.41834271922767496,
      "grad_norm": 0.23526298999786377,
      "learning_rate": 1.989247311827957e-05,
      "loss": 0.0286,
      "step": 65
    },
    {
      "epoch": 0.4247787610619469,
      "grad_norm": 0.2829250395298004,
      "learning_rate": 1.9856630824372764e-05,
      "loss": 0.0156,
      "step": 66
    },
    {
      "epoch": 0.43121480289621883,
      "grad_norm": 0.15569880604743958,
      "learning_rate": 1.9820788530465953e-05,
      "loss": 0.0082,
      "step": 67
    },
    {
      "epoch": 0.43765084473049076,
      "grad_norm": 0.5254403948783875,
      "learning_rate": 1.978494623655914e-05,
      "loss": 0.0262,
      "step": 68
    },
    {
      "epoch": 0.4440868865647627,
      "grad_norm": 0.2878986895084381,
      "learning_rate": 1.9749103942652334e-05,
      "loss": 0.0227,
      "step": 69
    },
    {
      "epoch": 0.4505229283990346,
      "grad_norm": 0.4444940686225891,
      "learning_rate": 1.9713261648745522e-05,
      "loss": 0.4635,
      "step": 70
    },
    {
      "epoch": 0.4569589702333065,
      "grad_norm": 0.1892196536064148,
      "learning_rate": 1.967741935483871e-05,
      "loss": 0.0146,
      "step": 71
    },
    {
      "epoch": 0.46339501206757844,
      "grad_norm": 0.2737014889717102,
      "learning_rate": 1.9641577060931903e-05,
      "loss": 0.0243,
      "step": 72
    },
    {
      "epoch": 0.46983105390185037,
      "grad_norm": 0.21952803432941437,
      "learning_rate": 1.9605734767025092e-05,
      "loss": 0.0263,
      "step": 73
    },
    {
      "epoch": 0.4762670957361223,
      "grad_norm": 0.22916734218597412,
      "learning_rate": 1.956989247311828e-05,
      "loss": 0.0236,
      "step": 74
    },
    {
      "epoch": 0.4827031375703942,
      "grad_norm": 0.3466736376285553,
      "learning_rate": 1.953405017921147e-05,
      "loss": 0.4588,
      "step": 75
    },
    {
      "epoch": 0.4891391794046661,
      "grad_norm": 0.5918274521827698,
      "learning_rate": 1.9498207885304662e-05,
      "loss": 0.0441,
      "step": 76
    },
    {
      "epoch": 0.49557522123893805,
      "grad_norm": 0.459730327129364,
      "learning_rate": 1.946236559139785e-05,
      "loss": 0.4551,
      "step": 77
    },
    {
      "epoch": 0.50201126307321,
      "grad_norm": 0.23603028059005737,
      "learning_rate": 1.942652329749104e-05,
      "loss": 0.0364,
      "step": 78
    },
    {
      "epoch": 0.5084473049074819,
      "grad_norm": 0.4434477686882019,
      "learning_rate": 1.9390681003584232e-05,
      "loss": 0.0404,
      "step": 79
    },
    {
      "epoch": 0.5148833467417538,
      "grad_norm": 0.19133949279785156,
      "learning_rate": 1.935483870967742e-05,
      "loss": 0.0111,
      "step": 80
    },
    {
      "epoch": 0.5213193885760258,
      "grad_norm": 0.1613936573266983,
      "learning_rate": 1.931899641577061e-05,
      "loss": 0.008,
      "step": 81
    },
    {
      "epoch": 0.5277554304102977,
      "grad_norm": 0.1911739706993103,
      "learning_rate": 1.9283154121863802e-05,
      "loss": 0.0211,
      "step": 82
    },
    {
      "epoch": 0.5341914722445696,
      "grad_norm": 0.09587256610393524,
      "learning_rate": 1.924731182795699e-05,
      "loss": 0.0051,
      "step": 83
    },
    {
      "epoch": 0.5406275140788415,
      "grad_norm": 0.13228380680084229,
      "learning_rate": 1.921146953405018e-05,
      "loss": 0.0274,
      "step": 84
    },
    {
      "epoch": 0.5470635559131134,
      "grad_norm": 0.3289845585823059,
      "learning_rate": 1.9175627240143372e-05,
      "loss": 0.0301,
      "step": 85
    },
    {
      "epoch": 0.5534995977473853,
      "grad_norm": 0.2110464870929718,
      "learning_rate": 1.913978494623656e-05,
      "loss": 0.0278,
      "step": 86
    },
    {
      "epoch": 0.5599356395816573,
      "grad_norm": 0.12677668035030365,
      "learning_rate": 1.910394265232975e-05,
      "loss": 0.0243,
      "step": 87
    },
    {
      "epoch": 0.5663716814159292,
      "grad_norm": 0.18576140701770782,
      "learning_rate": 1.906810035842294e-05,
      "loss": 0.0105,
      "step": 88
    },
    {
      "epoch": 0.5728077232502011,
      "grad_norm": 0.1869700849056244,
      "learning_rate": 1.903225806451613e-05,
      "loss": 0.0095,
      "step": 89
    },
    {
      "epoch": 0.5792437650844731,
      "grad_norm": 0.09644640237092972,
      "learning_rate": 1.899641577060932e-05,
      "loss": 0.0154,
      "step": 90
    },
    {
      "epoch": 0.585679806918745,
      "grad_norm": 0.2880946099758148,
      "learning_rate": 1.896057347670251e-05,
      "loss": 0.4442,
      "step": 91
    },
    {
      "epoch": 0.5921158487530169,
      "grad_norm": 0.29044315218925476,
      "learning_rate": 1.89247311827957e-05,
      "loss": 0.0173,
      "step": 92
    },
    {
      "epoch": 0.5985518905872889,
      "grad_norm": 0.1388779878616333,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0161,
      "step": 93
    },
    {
      "epoch": 0.6049879324215608,
      "grad_norm": 0.09695686399936676,
      "learning_rate": 1.885304659498208e-05,
      "loss": 0.0141,
      "step": 94
    },
    {
      "epoch": 0.6114239742558326,
      "grad_norm": 0.27868297696113586,
      "learning_rate": 1.881720430107527e-05,
      "loss": 0.4628,
      "step": 95
    },
    {
      "epoch": 0.6178600160901045,
      "grad_norm": 0.3495396673679352,
      "learning_rate": 1.878136200716846e-05,
      "loss": 0.4753,
      "step": 96
    },
    {
      "epoch": 0.6242960579243765,
      "grad_norm": 0.2866361737251282,
      "learning_rate": 1.874551971326165e-05,
      "loss": 0.4443,
      "step": 97
    },
    {
      "epoch": 0.6307320997586484,
      "grad_norm": 0.23912052810192108,
      "learning_rate": 1.870967741935484e-05,
      "loss": 0.0099,
      "step": 98
    },
    {
      "epoch": 0.6371681415929203,
      "grad_norm": 0.26591575145721436,
      "learning_rate": 1.867383512544803e-05,
      "loss": 0.0351,
      "step": 99
    },
    {
      "epoch": 0.6436041834271923,
      "grad_norm": 0.1144983097910881,
      "learning_rate": 1.863799283154122e-05,
      "loss": 0.0186,
      "step": 100
    },
    {
      "epoch": 0.6436041834271923,
      "eval_loss": 0.1680396944284439,
      "eval_runtime": 51.2996,
      "eval_samples_per_second": 24.23,
      "eval_steps_per_second": 1.52,
      "step": 100
    },
    {
      "epoch": 0.6500402252614642,
      "grad_norm": 0.28065112233161926,
      "learning_rate": 1.860215053763441e-05,
      "loss": 0.031,
      "step": 101
    },
    {
      "epoch": 0.6564762670957361,
      "grad_norm": 0.3458935022354126,
      "learning_rate": 1.85663082437276e-05,
      "loss": 0.0441,
      "step": 102
    },
    {
      "epoch": 0.6629123089300081,
      "grad_norm": 0.4275907278060913,
      "learning_rate": 1.853046594982079e-05,
      "loss": 0.0219,
      "step": 103
    },
    {
      "epoch": 0.66934835076428,
      "grad_norm": 0.14996258914470673,
      "learning_rate": 1.849462365591398e-05,
      "loss": 0.0198,
      "step": 104
    },
    {
      "epoch": 0.6757843925985519,
      "grad_norm": 0.21788328886032104,
      "learning_rate": 1.845878136200717e-05,
      "loss": 0.0154,
      "step": 105
    },
    {
      "epoch": 0.6822204344328238,
      "grad_norm": 0.15431095659732819,
      "learning_rate": 1.842293906810036e-05,
      "loss": 0.0218,
      "step": 106
    },
    {
      "epoch": 0.6886564762670957,
      "grad_norm": 0.31165817379951477,
      "learning_rate": 1.838709677419355e-05,
      "loss": 0.4103,
      "step": 107
    },
    {
      "epoch": 0.6950925181013676,
      "grad_norm": 0.2639606297016144,
      "learning_rate": 1.835125448028674e-05,
      "loss": 0.0103,
      "step": 108
    },
    {
      "epoch": 0.7015285599356396,
      "grad_norm": 0.46549728512763977,
      "learning_rate": 1.831541218637993e-05,
      "loss": 0.0332,
      "step": 109
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 0.29281044006347656,
      "learning_rate": 1.827956989247312e-05,
      "loss": 0.027,
      "step": 110
    },
    {
      "epoch": 0.7144006436041834,
      "grad_norm": 0.3910105228424072,
      "learning_rate": 1.824372759856631e-05,
      "loss": 0.4625,
      "step": 111
    },
    {
      "epoch": 0.7208366854384554,
      "grad_norm": 0.34580114483833313,
      "learning_rate": 1.82078853046595e-05,
      "loss": 0.4175,
      "step": 112
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 0.29711267352104187,
      "learning_rate": 1.817204301075269e-05,
      "loss": 0.4349,
      "step": 113
    },
    {
      "epoch": 0.7337087691069992,
      "grad_norm": 0.3359336256980896,
      "learning_rate": 1.8136200716845878e-05,
      "loss": 0.0387,
      "step": 114
    },
    {
      "epoch": 0.7401448109412712,
      "grad_norm": 0.4495493173599243,
      "learning_rate": 1.810035842293907e-05,
      "loss": 0.4147,
      "step": 115
    },
    {
      "epoch": 0.7465808527755431,
      "grad_norm": 0.14975562691688538,
      "learning_rate": 1.806451612903226e-05,
      "loss": 0.0165,
      "step": 116
    },
    {
      "epoch": 0.7530168946098149,
      "grad_norm": 3.006089925765991,
      "learning_rate": 1.802867383512545e-05,
      "loss": 0.745,
      "step": 117
    },
    {
      "epoch": 0.7594529364440868,
      "grad_norm": 0.09801539033651352,
      "learning_rate": 1.799283154121864e-05,
      "loss": 0.0118,
      "step": 118
    },
    {
      "epoch": 0.7658889782783588,
      "grad_norm": 0.27284809947013855,
      "learning_rate": 1.795698924731183e-05,
      "loss": 0.4103,
      "step": 119
    },
    {
      "epoch": 0.7723250201126307,
      "grad_norm": 0.16429510712623596,
      "learning_rate": 1.792114695340502e-05,
      "loss": 0.0297,
      "step": 120
    },
    {
      "epoch": 0.7787610619469026,
      "grad_norm": 0.22823089361190796,
      "learning_rate": 1.7885304659498207e-05,
      "loss": 0.032,
      "step": 121
    },
    {
      "epoch": 0.7851971037811746,
      "grad_norm": 0.2850692570209503,
      "learning_rate": 1.78494623655914e-05,
      "loss": 0.0219,
      "step": 122
    },
    {
      "epoch": 0.7916331456154465,
      "grad_norm": 0.13170762360095978,
      "learning_rate": 1.781362007168459e-05,
      "loss": 0.0236,
      "step": 123
    },
    {
      "epoch": 0.7980691874497184,
      "grad_norm": 0.2705281376838684,
      "learning_rate": 1.7777777777777777e-05,
      "loss": 0.026,
      "step": 124
    },
    {
      "epoch": 0.8045052292839904,
      "grad_norm": 0.13744159042835236,
      "learning_rate": 1.774193548387097e-05,
      "loss": 0.0158,
      "step": 125
    },
    {
      "epoch": 0.8109412711182623,
      "grad_norm": 2.236666679382324,
      "learning_rate": 1.770609318996416e-05,
      "loss": 0.5873,
      "step": 126
    },
    {
      "epoch": 0.8173773129525342,
      "grad_norm": 0.47804903984069824,
      "learning_rate": 1.767025089605735e-05,
      "loss": 0.8643,
      "step": 127
    },
    {
      "epoch": 0.8238133547868061,
      "grad_norm": 0.6117232441902161,
      "learning_rate": 1.763440860215054e-05,
      "loss": 0.4439,
      "step": 128
    },
    {
      "epoch": 0.830249396621078,
      "grad_norm": 0.2589556574821472,
      "learning_rate": 1.759856630824373e-05,
      "loss": 0.0186,
      "step": 129
    },
    {
      "epoch": 0.8366854384553499,
      "grad_norm": 0.1313331127166748,
      "learning_rate": 1.756272401433692e-05,
      "loss": 0.0197,
      "step": 130
    },
    {
      "epoch": 0.8431214802896219,
      "grad_norm": 0.25308552384376526,
      "learning_rate": 1.752688172043011e-05,
      "loss": 0.0233,
      "step": 131
    },
    {
      "epoch": 0.8495575221238938,
      "grad_norm": 0.28576380014419556,
      "learning_rate": 1.74910394265233e-05,
      "loss": 0.034,
      "step": 132
    },
    {
      "epoch": 0.8559935639581657,
      "grad_norm": 0.2891015410423279,
      "learning_rate": 1.745519713261649e-05,
      "loss": 0.4216,
      "step": 133
    },
    {
      "epoch": 0.8624296057924377,
      "grad_norm": 0.27803030610084534,
      "learning_rate": 1.741935483870968e-05,
      "loss": 0.3943,
      "step": 134
    },
    {
      "epoch": 0.8688656476267096,
      "grad_norm": 0.11502058804035187,
      "learning_rate": 1.738351254480287e-05,
      "loss": 0.02,
      "step": 135
    },
    {
      "epoch": 0.8753016894609815,
      "grad_norm": 0.25538817048072815,
      "learning_rate": 1.734767025089606e-05,
      "loss": 0.4296,
      "step": 136
    },
    {
      "epoch": 0.8817377312952535,
      "grad_norm": 0.32091885805130005,
      "learning_rate": 1.7311827956989248e-05,
      "loss": 0.0154,
      "step": 137
    },
    {
      "epoch": 0.8881737731295254,
      "grad_norm": 0.2970452308654785,
      "learning_rate": 1.727598566308244e-05,
      "loss": 0.4075,
      "step": 138
    },
    {
      "epoch": 0.8946098149637972,
      "grad_norm": 0.1838112473487854,
      "learning_rate": 1.724014336917563e-05,
      "loss": 0.0232,
      "step": 139
    },
    {
      "epoch": 0.9010458567980691,
      "grad_norm": 0.16923215985298157,
      "learning_rate": 1.7204301075268818e-05,
      "loss": 0.0282,
      "step": 140
    },
    {
      "epoch": 0.9074818986323411,
      "grad_norm": 0.16034924983978271,
      "learning_rate": 1.716845878136201e-05,
      "loss": 0.0148,
      "step": 141
    },
    {
      "epoch": 0.913917940466613,
      "grad_norm": 0.11954563111066818,
      "learning_rate": 1.71326164874552e-05,
      "loss": 0.0065,
      "step": 142
    },
    {
      "epoch": 0.9203539823008849,
      "grad_norm": 0.11379079520702362,
      "learning_rate": 1.7096774193548388e-05,
      "loss": 0.0107,
      "step": 143
    },
    {
      "epoch": 0.9267900241351569,
      "grad_norm": 0.15797589719295502,
      "learning_rate": 1.7060931899641577e-05,
      "loss": 0.0164,
      "step": 144
    },
    {
      "epoch": 0.9332260659694288,
      "grad_norm": 0.08926993608474731,
      "learning_rate": 1.702508960573477e-05,
      "loss": 0.0152,
      "step": 145
    },
    {
      "epoch": 0.9396621078037007,
      "grad_norm": 0.21863508224487305,
      "learning_rate": 1.6989247311827958e-05,
      "loss": 0.0328,
      "step": 146
    },
    {
      "epoch": 0.9460981496379727,
      "grad_norm": 0.19935736060142517,
      "learning_rate": 1.6953405017921147e-05,
      "loss": 0.0147,
      "step": 147
    },
    {
      "epoch": 0.9525341914722446,
      "grad_norm": 1.2910375595092773,
      "learning_rate": 1.691756272401434e-05,
      "loss": 0.8354,
      "step": 148
    },
    {
      "epoch": 0.9589702333065165,
      "grad_norm": 0.5713352560997009,
      "learning_rate": 1.6881720430107528e-05,
      "loss": 0.8467,
      "step": 149
    },
    {
      "epoch": 0.9654062751407884,
      "grad_norm": 0.39240339398384094,
      "learning_rate": 1.6845878136200717e-05,
      "loss": 0.0271,
      "step": 150
    },
    {
      "epoch": 0.9654062751407884,
      "eval_loss": 0.1599850207567215,
      "eval_runtime": 51.3273,
      "eval_samples_per_second": 24.217,
      "eval_steps_per_second": 1.52,
      "step": 150
    },
    {
      "epoch": 0.9718423169750603,
      "grad_norm": 0.1560189127922058,
      "learning_rate": 1.681003584229391e-05,
      "loss": 0.0258,
      "step": 151
    },
    {
      "epoch": 0.9782783588093322,
      "grad_norm": 0.4518415331840515,
      "learning_rate": 1.6774193548387098e-05,
      "loss": 0.0299,
      "step": 152
    },
    {
      "epoch": 0.9847144006436042,
      "grad_norm": 0.10945042222738266,
      "learning_rate": 1.6738351254480286e-05,
      "loss": 0.013,
      "step": 153
    },
    {
      "epoch": 0.9911504424778761,
      "grad_norm": 0.17007307708263397,
      "learning_rate": 1.670250896057348e-05,
      "loss": 0.0212,
      "step": 154
    },
    {
      "epoch": 0.997586484312148,
      "grad_norm": 0.38188406825065613,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.4192,
      "step": 155
    },
    {
      "epoch": 1.006436041834272,
      "grad_norm": 0.252238005399704,
      "learning_rate": 1.6630824372759856e-05,
      "loss": 0.0118,
      "step": 156
    },
    {
      "epoch": 1.0128720836685439,
      "grad_norm": 0.11915785074234009,
      "learning_rate": 1.659498207885305e-05,
      "loss": 0.0106,
      "step": 157
    },
    {
      "epoch": 1.0193081255028158,
      "grad_norm": 0.3643169701099396,
      "learning_rate": 1.6559139784946237e-05,
      "loss": 0.448,
      "step": 158
    },
    {
      "epoch": 1.0257441673370877,
      "grad_norm": 0.39169442653656006,
      "learning_rate": 1.6523297491039426e-05,
      "loss": 0.3981,
      "step": 159
    },
    {
      "epoch": 1.0321802091713597,
      "grad_norm": 0.12716004252433777,
      "learning_rate": 1.648745519713262e-05,
      "loss": 0.0073,
      "step": 160
    },
    {
      "epoch": 1.0386162510056316,
      "grad_norm": 0.27380505204200745,
      "learning_rate": 1.6451612903225807e-05,
      "loss": 0.0312,
      "step": 161
    },
    {
      "epoch": 1.0450522928399035,
      "grad_norm": 0.2114812582731247,
      "learning_rate": 1.6415770609318996e-05,
      "loss": 0.0143,
      "step": 162
    },
    {
      "epoch": 1.0514883346741755,
      "grad_norm": 0.126071035861969,
      "learning_rate": 1.6379928315412188e-05,
      "loss": 0.0163,
      "step": 163
    },
    {
      "epoch": 1.0579243765084474,
      "grad_norm": 0.21109126508235931,
      "learning_rate": 1.6344086021505377e-05,
      "loss": 0.0134,
      "step": 164
    },
    {
      "epoch": 1.0643604183427193,
      "grad_norm": 0.35016992688179016,
      "learning_rate": 1.6308243727598566e-05,
      "loss": 0.0289,
      "step": 165
    },
    {
      "epoch": 1.0707964601769913,
      "grad_norm": 0.22815284132957458,
      "learning_rate": 1.6272401433691758e-05,
      "loss": 0.0079,
      "step": 166
    },
    {
      "epoch": 1.077232502011263,
      "grad_norm": 0.18351241946220398,
      "learning_rate": 1.6236559139784947e-05,
      "loss": 0.0335,
      "step": 167
    },
    {
      "epoch": 1.083668543845535,
      "grad_norm": 0.16529692709445953,
      "learning_rate": 1.6200716845878136e-05,
      "loss": 0.0211,
      "step": 168
    },
    {
      "epoch": 1.0901045856798068,
      "grad_norm": 0.09043474495410919,
      "learning_rate": 1.6164874551971328e-05,
      "loss": 0.0142,
      "step": 169
    },
    {
      "epoch": 1.0965406275140788,
      "grad_norm": 0.7626616954803467,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 0.0498,
      "step": 170
    },
    {
      "epoch": 1.1029766693483507,
      "grad_norm": 0.4290405213832855,
      "learning_rate": 1.6093189964157706e-05,
      "loss": 0.454,
      "step": 171
    },
    {
      "epoch": 1.1094127111826226,
      "grad_norm": 0.1875208020210266,
      "learning_rate": 1.6057347670250898e-05,
      "loss": 0.0286,
      "step": 172
    },
    {
      "epoch": 1.1158487530168946,
      "grad_norm": 0.2726469039916992,
      "learning_rate": 1.6021505376344087e-05,
      "loss": 0.0387,
      "step": 173
    },
    {
      "epoch": 1.1222847948511665,
      "grad_norm": 0.47170892357826233,
      "learning_rate": 1.5985663082437275e-05,
      "loss": 0.4012,
      "step": 174
    },
    {
      "epoch": 1.1287208366854384,
      "grad_norm": 0.34112417697906494,
      "learning_rate": 1.5949820788530468e-05,
      "loss": 0.3481,
      "step": 175
    },
    {
      "epoch": 1.1351568785197104,
      "grad_norm": 0.11137203872203827,
      "learning_rate": 1.5913978494623657e-05,
      "loss": 0.0132,
      "step": 176
    },
    {
      "epoch": 1.1415929203539823,
      "grad_norm": 0.27115076780319214,
      "learning_rate": 1.587813620071685e-05,
      "loss": 0.0259,
      "step": 177
    },
    {
      "epoch": 1.1480289621882542,
      "grad_norm": 0.3851676285266876,
      "learning_rate": 1.5842293906810038e-05,
      "loss": 0.4044,
      "step": 178
    },
    {
      "epoch": 1.1544650040225262,
      "grad_norm": 0.23364827036857605,
      "learning_rate": 1.5806451612903226e-05,
      "loss": 0.0283,
      "step": 179
    },
    {
      "epoch": 1.160901045856798,
      "grad_norm": 0.4647335410118103,
      "learning_rate": 1.577060931899642e-05,
      "loss": 0.4407,
      "step": 180
    },
    {
      "epoch": 1.16733708769107,
      "grad_norm": 0.20641814172267914,
      "learning_rate": 1.5734767025089607e-05,
      "loss": 0.0252,
      "step": 181
    },
    {
      "epoch": 1.173773129525342,
      "grad_norm": 0.3389538824558258,
      "learning_rate": 1.5698924731182796e-05,
      "loss": 0.0452,
      "step": 182
    },
    {
      "epoch": 1.180209171359614,
      "grad_norm": 0.5019474625587463,
      "learning_rate": 1.566308243727599e-05,
      "loss": 0.0601,
      "step": 183
    },
    {
      "epoch": 1.1866452131938858,
      "grad_norm": 0.16338226199150085,
      "learning_rate": 1.5627240143369177e-05,
      "loss": 0.0204,
      "step": 184
    },
    {
      "epoch": 1.1930812550281578,
      "grad_norm": 0.19972220063209534,
      "learning_rate": 1.5591397849462366e-05,
      "loss": 0.0235,
      "step": 185
    },
    {
      "epoch": 1.1995172968624297,
      "grad_norm": 0.41545209288597107,
      "learning_rate": 1.555555555555556e-05,
      "loss": 0.021,
      "step": 186
    },
    {
      "epoch": 1.2059533386967014,
      "grad_norm": 0.3248477876186371,
      "learning_rate": 1.5519713261648747e-05,
      "loss": 0.026,
      "step": 187
    },
    {
      "epoch": 1.2123893805309733,
      "grad_norm": 0.14145104587078094,
      "learning_rate": 1.5483870967741936e-05,
      "loss": 0.0284,
      "step": 188
    },
    {
      "epoch": 1.2188254223652453,
      "grad_norm": 0.40942469239234924,
      "learning_rate": 1.5448028673835128e-05,
      "loss": 0.3606,
      "step": 189
    },
    {
      "epoch": 1.2252614641995172,
      "grad_norm": 0.5227411389350891,
      "learning_rate": 1.5412186379928317e-05,
      "loss": 0.3709,
      "step": 190
    },
    {
      "epoch": 1.2316975060337891,
      "grad_norm": 0.11880698800086975,
      "learning_rate": 1.5376344086021506e-05,
      "loss": 0.0254,
      "step": 191
    },
    {
      "epoch": 1.238133547868061,
      "grad_norm": 0.39693182706832886,
      "learning_rate": 1.5340501792114698e-05,
      "loss": 0.2878,
      "step": 192
    },
    {
      "epoch": 1.244569589702333,
      "grad_norm": 1.0852547883987427,
      "learning_rate": 1.5304659498207887e-05,
      "loss": 0.3955,
      "step": 193
    },
    {
      "epoch": 1.251005631536605,
      "grad_norm": 0.2036651223897934,
      "learning_rate": 1.5268817204301076e-05,
      "loss": 0.0372,
      "step": 194
    },
    {
      "epoch": 1.2574416733708769,
      "grad_norm": 0.17673686146736145,
      "learning_rate": 1.5232974910394266e-05,
      "loss": 0.0174,
      "step": 195
    },
    {
      "epoch": 1.2638777152051488,
      "grad_norm": 0.4515330195426941,
      "learning_rate": 1.5197132616487455e-05,
      "loss": 0.3364,
      "step": 196
    },
    {
      "epoch": 1.2703137570394207,
      "grad_norm": 0.17701172828674316,
      "learning_rate": 1.5161290322580646e-05,
      "loss": 0.0119,
      "step": 197
    },
    {
      "epoch": 1.2767497988736927,
      "grad_norm": 0.11913938075304031,
      "learning_rate": 1.5125448028673838e-05,
      "loss": 0.014,
      "step": 198
    },
    {
      "epoch": 1.2831858407079646,
      "grad_norm": 0.1764993667602539,
      "learning_rate": 1.5089605734767025e-05,
      "loss": 0.0148,
      "step": 199
    },
    {
      "epoch": 1.2896218825422365,
      "grad_norm": 0.17357245087623596,
      "learning_rate": 1.5053763440860215e-05,
      "loss": 0.0147,
      "step": 200
    },
    {
      "epoch": 1.2896218825422365,
      "eval_loss": 0.14379338920116425,
      "eval_runtime": 52.5718,
      "eval_samples_per_second": 23.644,
      "eval_steps_per_second": 1.484,
      "step": 200
    },
    {
      "epoch": 1.2960579243765085,
      "grad_norm": 0.08262718468904495,
      "learning_rate": 1.5017921146953408e-05,
      "loss": 0.0167,
      "step": 201
    },
    {
      "epoch": 1.3024939662107804,
      "grad_norm": 0.11983931064605713,
      "learning_rate": 1.4982078853046595e-05,
      "loss": 0.0124,
      "step": 202
    },
    {
      "epoch": 1.3089300080450523,
      "grad_norm": 0.1335660219192505,
      "learning_rate": 1.4946236559139787e-05,
      "loss": 0.029,
      "step": 203
    },
    {
      "epoch": 1.3153660498793243,
      "grad_norm": 0.15403258800506592,
      "learning_rate": 1.4910394265232978e-05,
      "loss": 0.0247,
      "step": 204
    },
    {
      "epoch": 1.3218020917135962,
      "grad_norm": 0.13575050234794617,
      "learning_rate": 1.4874551971326165e-05,
      "loss": 0.0061,
      "step": 205
    },
    {
      "epoch": 1.3282381335478681,
      "grad_norm": 0.1604815572500229,
      "learning_rate": 1.4838709677419357e-05,
      "loss": 0.0077,
      "step": 206
    },
    {
      "epoch": 1.33467417538214,
      "grad_norm": 0.12911377847194672,
      "learning_rate": 1.4802867383512547e-05,
      "loss": 0.0228,
      "step": 207
    },
    {
      "epoch": 1.341110217216412,
      "grad_norm": 0.5886266827583313,
      "learning_rate": 1.4767025089605736e-05,
      "loss": 0.3971,
      "step": 208
    },
    {
      "epoch": 1.347546259050684,
      "grad_norm": 0.21684783697128296,
      "learning_rate": 1.4731182795698927e-05,
      "loss": 0.013,
      "step": 209
    },
    {
      "epoch": 1.3539823008849559,
      "grad_norm": 0.5281780958175659,
      "learning_rate": 1.4695340501792117e-05,
      "loss": 0.3232,
      "step": 210
    },
    {
      "epoch": 1.3604183427192278,
      "grad_norm": 0.19906924664974213,
      "learning_rate": 1.4659498207885306e-05,
      "loss": 0.0223,
      "step": 211
    },
    {
      "epoch": 1.3668543845534997,
      "grad_norm": 0.1637355536222458,
      "learning_rate": 1.4623655913978497e-05,
      "loss": 0.0138,
      "step": 212
    },
    {
      "epoch": 1.3732904263877717,
      "grad_norm": 1.2885085344314575,
      "learning_rate": 1.4587813620071687e-05,
      "loss": 1.0724,
      "step": 213
    },
    {
      "epoch": 1.3797264682220434,
      "grad_norm": 0.5505703091621399,
      "learning_rate": 1.4551971326164876e-05,
      "loss": 0.3286,
      "step": 214
    },
    {
      "epoch": 1.3861625100563153,
      "grad_norm": 0.1638670265674591,
      "learning_rate": 1.4516129032258066e-05,
      "loss": 0.0172,
      "step": 215
    },
    {
      "epoch": 1.3925985518905872,
      "grad_norm": 0.2526549994945526,
      "learning_rate": 1.4480286738351255e-05,
      "loss": 0.0144,
      "step": 216
    },
    {
      "epoch": 1.3990345937248592,
      "grad_norm": 0.20205208659172058,
      "learning_rate": 1.4444444444444446e-05,
      "loss": 0.0259,
      "step": 217
    },
    {
      "epoch": 1.405470635559131,
      "grad_norm": 0.5266739130020142,
      "learning_rate": 1.4408602150537636e-05,
      "loss": 0.3745,
      "step": 218
    },
    {
      "epoch": 1.411906677393403,
      "grad_norm": 0.24302096664905548,
      "learning_rate": 1.4372759856630825e-05,
      "loss": 0.0272,
      "step": 219
    },
    {
      "epoch": 1.418342719227675,
      "grad_norm": 0.17684873938560486,
      "learning_rate": 1.4336917562724016e-05,
      "loss": 0.0247,
      "step": 220
    },
    {
      "epoch": 1.424778761061947,
      "grad_norm": 0.25916844606399536,
      "learning_rate": 1.4301075268817206e-05,
      "loss": 0.0326,
      "step": 221
    },
    {
      "epoch": 1.4312148028962188,
      "grad_norm": 0.18102584779262543,
      "learning_rate": 1.4265232974910395e-05,
      "loss": 0.0127,
      "step": 222
    },
    {
      "epoch": 1.4376508447304908,
      "grad_norm": 0.3805677890777588,
      "learning_rate": 1.4229390681003586e-05,
      "loss": 0.0249,
      "step": 223
    },
    {
      "epoch": 1.4440868865647627,
      "grad_norm": 0.21192020177841187,
      "learning_rate": 1.4193548387096776e-05,
      "loss": 0.0316,
      "step": 224
    },
    {
      "epoch": 1.4505229283990346,
      "grad_norm": 1.0858547687530518,
      "learning_rate": 1.4157706093189965e-05,
      "loss": 0.3269,
      "step": 225
    },
    {
      "epoch": 1.4569589702333066,
      "grad_norm": 0.09194491058588028,
      "learning_rate": 1.4121863799283155e-05,
      "loss": 0.0068,
      "step": 226
    },
    {
      "epoch": 1.4633950120675785,
      "grad_norm": 0.11517920345067978,
      "learning_rate": 1.4086021505376346e-05,
      "loss": 0.0087,
      "step": 227
    },
    {
      "epoch": 1.4698310539018504,
      "grad_norm": 0.16972172260284424,
      "learning_rate": 1.4050179211469535e-05,
      "loss": 0.02,
      "step": 228
    },
    {
      "epoch": 1.4762670957361224,
      "grad_norm": 0.110064797103405,
      "learning_rate": 1.4014336917562725e-05,
      "loss": 0.0119,
      "step": 229
    },
    {
      "epoch": 1.482703137570394,
      "grad_norm": 0.1085485965013504,
      "learning_rate": 1.3978494623655916e-05,
      "loss": 0.0097,
      "step": 230
    },
    {
      "epoch": 1.489139179404666,
      "grad_norm": 0.7314229011535645,
      "learning_rate": 1.3942652329749105e-05,
      "loss": 0.3103,
      "step": 231
    },
    {
      "epoch": 1.495575221238938,
      "grad_norm": 0.834983229637146,
      "learning_rate": 1.3906810035842295e-05,
      "loss": 0.3349,
      "step": 232
    },
    {
      "epoch": 1.5020112630732099,
      "grad_norm": 0.1254241168498993,
      "learning_rate": 1.3870967741935486e-05,
      "loss": 0.0121,
      "step": 233
    },
    {
      "epoch": 1.5084473049074818,
      "grad_norm": 0.72543865442276,
      "learning_rate": 1.3835125448028674e-05,
      "loss": 0.3146,
      "step": 234
    },
    {
      "epoch": 1.5148833467417537,
      "grad_norm": 0.10620654374361038,
      "learning_rate": 1.3799283154121865e-05,
      "loss": 0.0149,
      "step": 235
    },
    {
      "epoch": 1.5213193885760257,
      "grad_norm": 0.14484459161758423,
      "learning_rate": 1.3763440860215056e-05,
      "loss": 0.0116,
      "step": 236
    },
    {
      "epoch": 1.5277554304102976,
      "grad_norm": 0.9990514516830444,
      "learning_rate": 1.3727598566308244e-05,
      "loss": 0.2784,
      "step": 237
    },
    {
      "epoch": 1.5341914722445695,
      "grad_norm": 0.1340092271566391,
      "learning_rate": 1.3691756272401435e-05,
      "loss": 0.0113,
      "step": 238
    },
    {
      "epoch": 1.5406275140788415,
      "grad_norm": 0.17941772937774658,
      "learning_rate": 1.3655913978494624e-05,
      "loss": 0.0147,
      "step": 239
    },
    {
      "epoch": 1.5470635559131134,
      "grad_norm": 0.8962600827217102,
      "learning_rate": 1.3620071684587814e-05,
      "loss": 0.2442,
      "step": 240
    },
    {
      "epoch": 1.5534995977473853,
      "grad_norm": 0.14383266866207123,
      "learning_rate": 1.3584229390681005e-05,
      "loss": 0.0155,
      "step": 241
    },
    {
      "epoch": 1.5599356395816573,
      "grad_norm": 0.243489608168602,
      "learning_rate": 1.3548387096774194e-05,
      "loss": 0.0324,
      "step": 242
    },
    {
      "epoch": 1.5663716814159292,
      "grad_norm": 1.4162275791168213,
      "learning_rate": 1.3512544802867384e-05,
      "loss": 0.2416,
      "step": 243
    },
    {
      "epoch": 1.5728077232502011,
      "grad_norm": 0.2208283692598343,
      "learning_rate": 1.3476702508960575e-05,
      "loss": 0.0077,
      "step": 244
    },
    {
      "epoch": 1.579243765084473,
      "grad_norm": 0.14939089119434357,
      "learning_rate": 1.3440860215053763e-05,
      "loss": 0.009,
      "step": 245
    },
    {
      "epoch": 1.585679806918745,
      "grad_norm": 1.6077126264572144,
      "learning_rate": 1.3405017921146954e-05,
      "loss": 0.4116,
      "step": 246
    },
    {
      "epoch": 1.592115848753017,
      "grad_norm": 0.1547846794128418,
      "learning_rate": 1.3369175627240144e-05,
      "loss": 0.0179,
      "step": 247
    },
    {
      "epoch": 1.5985518905872889,
      "grad_norm": 0.7085920572280884,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.2002,
      "step": 248
    },
    {
      "epoch": 1.6049879324215608,
      "grad_norm": 0.34447571635246277,
      "learning_rate": 1.3297491039426524e-05,
      "loss": 0.0206,
      "step": 249
    },
    {
      "epoch": 1.6114239742558327,
      "grad_norm": 0.811907947063446,
      "learning_rate": 1.3261648745519714e-05,
      "loss": 0.1864,
      "step": 250
    },
    {
      "epoch": 1.6114239742558327,
      "eval_loss": 0.07760386914014816,
      "eval_runtime": 51.7926,
      "eval_samples_per_second": 24.0,
      "eval_steps_per_second": 1.506,
      "step": 250
    },
    {
      "epoch": 1.6178600160901047,
      "grad_norm": 2.657496452331543,
      "learning_rate": 1.3225806451612903e-05,
      "loss": 0.5196,
      "step": 251
    },
    {
      "epoch": 1.6242960579243766,
      "grad_norm": 0.23258720338344574,
      "learning_rate": 1.3189964157706094e-05,
      "loss": 0.0284,
      "step": 252
    },
    {
      "epoch": 1.6307320997586485,
      "grad_norm": 1.0395914316177368,
      "learning_rate": 1.3154121863799286e-05,
      "loss": 0.2011,
      "step": 253
    },
    {
      "epoch": 1.6371681415929205,
      "grad_norm": 0.44999822974205017,
      "learning_rate": 1.3118279569892473e-05,
      "loss": 0.0406,
      "step": 254
    },
    {
      "epoch": 1.6436041834271924,
      "grad_norm": 0.5035614371299744,
      "learning_rate": 1.3082437275985664e-05,
      "loss": 0.1328,
      "step": 255
    },
    {
      "epoch": 1.6500402252614643,
      "grad_norm": 0.3445001542568207,
      "learning_rate": 1.3046594982078856e-05,
      "loss": 0.0423,
      "step": 256
    },
    {
      "epoch": 1.6564762670957363,
      "grad_norm": 0.2192353457212448,
      "learning_rate": 1.3010752688172043e-05,
      "loss": 0.0205,
      "step": 257
    },
    {
      "epoch": 1.6629123089300082,
      "grad_norm": 1.1648844480514526,
      "learning_rate": 1.2974910394265235e-05,
      "loss": 0.2949,
      "step": 258
    },
    {
      "epoch": 1.6693483507642801,
      "grad_norm": 0.318177193403244,
      "learning_rate": 1.2939068100358426e-05,
      "loss": 0.0213,
      "step": 259
    },
    {
      "epoch": 1.675784392598552,
      "grad_norm": 0.7669880986213684,
      "learning_rate": 1.2903225806451613e-05,
      "loss": 0.1422,
      "step": 260
    },
    {
      "epoch": 1.6822204344328238,
      "grad_norm": 0.3407306373119354,
      "learning_rate": 1.2867383512544805e-05,
      "loss": 0.0221,
      "step": 261
    },
    {
      "epoch": 1.6886564762670957,
      "grad_norm": 0.35115498304367065,
      "learning_rate": 1.2831541218637992e-05,
      "loss": 0.0175,
      "step": 262
    },
    {
      "epoch": 1.6950925181013676,
      "grad_norm": 1.7119945287704468,
      "learning_rate": 1.2795698924731184e-05,
      "loss": 0.3085,
      "step": 263
    },
    {
      "epoch": 1.7015285599356396,
      "grad_norm": 0.22064833343029022,
      "learning_rate": 1.2759856630824375e-05,
      "loss": 0.0284,
      "step": 264
    },
    {
      "epoch": 1.7079646017699115,
      "grad_norm": 0.29255130887031555,
      "learning_rate": 1.2724014336917564e-05,
      "loss": 0.0206,
      "step": 265
    },
    {
      "epoch": 1.7144006436041834,
      "grad_norm": 0.3826977014541626,
      "learning_rate": 1.2688172043010754e-05,
      "loss": 0.0404,
      "step": 266
    },
    {
      "epoch": 1.7208366854384554,
      "grad_norm": 0.44769322872161865,
      "learning_rate": 1.2652329749103945e-05,
      "loss": 0.0292,
      "step": 267
    },
    {
      "epoch": 1.7272727272727273,
      "grad_norm": 0.5032942891120911,
      "learning_rate": 1.2616487455197134e-05,
      "loss": 0.114,
      "step": 268
    },
    {
      "epoch": 1.7337087691069992,
      "grad_norm": 0.23614856600761414,
      "learning_rate": 1.2580645161290324e-05,
      "loss": 0.019,
      "step": 269
    },
    {
      "epoch": 1.7401448109412712,
      "grad_norm": 0.28898510336875916,
      "learning_rate": 1.2544802867383515e-05,
      "loss": 0.01,
      "step": 270
    },
    {
      "epoch": 1.746580852775543,
      "grad_norm": 0.2266853153705597,
      "learning_rate": 1.2508960573476703e-05,
      "loss": 0.0206,
      "step": 271
    },
    {
      "epoch": 1.7530168946098148,
      "grad_norm": 0.5648798942565918,
      "learning_rate": 1.2473118279569894e-05,
      "loss": 0.0513,
      "step": 272
    },
    {
      "epoch": 1.7594529364440867,
      "grad_norm": 0.31285056471824646,
      "learning_rate": 1.2437275985663084e-05,
      "loss": 0.0107,
      "step": 273
    },
    {
      "epoch": 1.7658889782783587,
      "grad_norm": 0.2443651705980301,
      "learning_rate": 1.2401433691756273e-05,
      "loss": 0.0214,
      "step": 274
    },
    {
      "epoch": 1.7723250201126306,
      "grad_norm": 0.19790807366371155,
      "learning_rate": 1.2365591397849464e-05,
      "loss": 0.0113,
      "step": 275
    },
    {
      "epoch": 1.7787610619469025,
      "grad_norm": 0.22038061916828156,
      "learning_rate": 1.2329749103942654e-05,
      "loss": 0.0265,
      "step": 276
    },
    {
      "epoch": 1.7851971037811745,
      "grad_norm": 0.2689865231513977,
      "learning_rate": 1.2293906810035843e-05,
      "loss": 0.0129,
      "step": 277
    },
    {
      "epoch": 1.7916331456154464,
      "grad_norm": 0.15595918893814087,
      "learning_rate": 1.2258064516129034e-05,
      "loss": 0.0213,
      "step": 278
    },
    {
      "epoch": 1.7980691874497183,
      "grad_norm": 0.5568548440933228,
      "learning_rate": 1.2222222222222224e-05,
      "loss": 0.1176,
      "step": 279
    },
    {
      "epoch": 1.8045052292839903,
      "grad_norm": 0.6493303775787354,
      "learning_rate": 1.2186379928315413e-05,
      "loss": 0.1437,
      "step": 280
    },
    {
      "epoch": 1.8109412711182622,
      "grad_norm": 0.22125886380672455,
      "learning_rate": 1.2150537634408604e-05,
      "loss": 0.0235,
      "step": 281
    },
    {
      "epoch": 1.8173773129525341,
      "grad_norm": 0.2660318613052368,
      "learning_rate": 1.2114695340501794e-05,
      "loss": 0.0344,
      "step": 282
    },
    {
      "epoch": 1.823813354786806,
      "grad_norm": 0.3164728283882141,
      "learning_rate": 1.2078853046594983e-05,
      "loss": 0.0265,
      "step": 283
    },
    {
      "epoch": 1.830249396621078,
      "grad_norm": 0.603866696357727,
      "learning_rate": 1.2043010752688173e-05,
      "loss": 0.1106,
      "step": 284
    },
    {
      "epoch": 1.83668543845535,
      "grad_norm": 0.47857043147087097,
      "learning_rate": 1.2007168458781362e-05,
      "loss": 0.1185,
      "step": 285
    },
    {
      "epoch": 1.8431214802896219,
      "grad_norm": 0.17548660933971405,
      "learning_rate": 1.1971326164874553e-05,
      "loss": 0.0265,
      "step": 286
    },
    {
      "epoch": 1.8495575221238938,
      "grad_norm": 0.22294777631759644,
      "learning_rate": 1.1935483870967743e-05,
      "loss": 0.0262,
      "step": 287
    },
    {
      "epoch": 1.8559935639581657,
      "grad_norm": 0.36888498067855835,
      "learning_rate": 1.1899641577060932e-05,
      "loss": 0.023,
      "step": 288
    },
    {
      "epoch": 1.8624296057924377,
      "grad_norm": 0.6293675899505615,
      "learning_rate": 1.1863799283154123e-05,
      "loss": 0.2062,
      "step": 289
    },
    {
      "epoch": 1.8688656476267096,
      "grad_norm": 0.7194609045982361,
      "learning_rate": 1.1827956989247313e-05,
      "loss": 0.1443,
      "step": 290
    },
    {
      "epoch": 1.8753016894609815,
      "grad_norm": 0.20198310911655426,
      "learning_rate": 1.1792114695340502e-05,
      "loss": 0.0154,
      "step": 291
    },
    {
      "epoch": 1.8817377312952535,
      "grad_norm": 0.7821667194366455,
      "learning_rate": 1.1756272401433692e-05,
      "loss": 0.1092,
      "step": 292
    },
    {
      "epoch": 1.8881737731295254,
      "grad_norm": 0.2868107557296753,
      "learning_rate": 1.1720430107526883e-05,
      "loss": 0.0378,
      "step": 293
    },
    {
      "epoch": 1.8946098149637973,
      "grad_norm": 0.23544466495513916,
      "learning_rate": 1.1684587813620072e-05,
      "loss": 0.0196,
      "step": 294
    },
    {
      "epoch": 1.9010458567980693,
      "grad_norm": 0.5680718421936035,
      "learning_rate": 1.1648745519713262e-05,
      "loss": 0.1295,
      "step": 295
    },
    {
      "epoch": 1.9074818986323412,
      "grad_norm": 0.2280830591917038,
      "learning_rate": 1.1612903225806453e-05,
      "loss": 0.0161,
      "step": 296
    },
    {
      "epoch": 1.9139179404666131,
      "grad_norm": 0.4343087375164032,
      "learning_rate": 1.1577060931899642e-05,
      "loss": 0.0275,
      "step": 297
    },
    {
      "epoch": 1.920353982300885,
      "grad_norm": 0.2830842137336731,
      "learning_rate": 1.1541218637992832e-05,
      "loss": 0.0194,
      "step": 298
    },
    {
      "epoch": 1.926790024135157,
      "grad_norm": 0.2619675397872925,
      "learning_rate": 1.1505376344086023e-05,
      "loss": 0.0208,
      "step": 299
    },
    {
      "epoch": 1.933226065969429,
      "grad_norm": 0.1299377977848053,
      "learning_rate": 1.1469534050179212e-05,
      "loss": 0.0077,
      "step": 300
    },
    {
      "epoch": 1.933226065969429,
      "eval_loss": 0.0520189069211483,
      "eval_runtime": 51.3801,
      "eval_samples_per_second": 24.192,
      "eval_steps_per_second": 1.518,
      "step": 300
    },
    {
      "epoch": 1.9396621078037009,
      "grad_norm": 0.17885422706604004,
      "learning_rate": 1.1433691756272402e-05,
      "loss": 0.0084,
      "step": 301
    },
    {
      "epoch": 1.9460981496379728,
      "grad_norm": 0.1783466339111328,
      "learning_rate": 1.1397849462365593e-05,
      "loss": 0.0114,
      "step": 302
    },
    {
      "epoch": 1.9525341914722447,
      "grad_norm": 0.20578886568546295,
      "learning_rate": 1.1362007168458781e-05,
      "loss": 0.0138,
      "step": 303
    },
    {
      "epoch": 1.9589702333065167,
      "grad_norm": 0.18704429268836975,
      "learning_rate": 1.1326164874551972e-05,
      "loss": 0.0163,
      "step": 304
    },
    {
      "epoch": 1.9654062751407884,
      "grad_norm": 0.7460532188415527,
      "learning_rate": 1.1290322580645164e-05,
      "loss": 0.1828,
      "step": 305
    },
    {
      "epoch": 1.9718423169750603,
      "grad_norm": 0.43440866470336914,
      "learning_rate": 1.1254480286738351e-05,
      "loss": 0.0921,
      "step": 306
    },
    {
      "epoch": 1.9782783588093322,
      "grad_norm": 0.16779224574565887,
      "learning_rate": 1.1218637992831542e-05,
      "loss": 0.024,
      "step": 307
    },
    {
      "epoch": 1.9847144006436042,
      "grad_norm": 0.28848186135292053,
      "learning_rate": 1.118279569892473e-05,
      "loss": 0.0147,
      "step": 308
    },
    {
      "epoch": 1.991150442477876,
      "grad_norm": 0.3030852973461151,
      "learning_rate": 1.1146953405017921e-05,
      "loss": 0.0131,
      "step": 309
    },
    {
      "epoch": 1.997586484312148,
      "grad_norm": 0.15969063341617584,
      "learning_rate": 1.1111111111111113e-05,
      "loss": 0.0063,
      "step": 310
    },
    {
      "epoch": 2.006436041834272,
      "grad_norm": 0.5159896016120911,
      "learning_rate": 1.10752688172043e-05,
      "loss": 0.0273,
      "step": 311
    },
    {
      "epoch": 2.012872083668544,
      "grad_norm": 0.42423754930496216,
      "learning_rate": 1.1039426523297491e-05,
      "loss": 0.0403,
      "step": 312
    },
    {
      "epoch": 2.019308125502816,
      "grad_norm": 2.0265703201293945,
      "learning_rate": 1.1003584229390683e-05,
      "loss": 0.2801,
      "step": 313
    },
    {
      "epoch": 2.0257441673370877,
      "grad_norm": 0.41678109765052795,
      "learning_rate": 1.096774193548387e-05,
      "loss": 0.1061,
      "step": 314
    },
    {
      "epoch": 2.0321802091713597,
      "grad_norm": 0.5575141310691833,
      "learning_rate": 1.0931899641577063e-05,
      "loss": 0.0304,
      "step": 315
    },
    {
      "epoch": 2.0386162510056316,
      "grad_norm": 0.38678252696990967,
      "learning_rate": 1.0896057347670253e-05,
      "loss": 0.1009,
      "step": 316
    },
    {
      "epoch": 2.0450522928399035,
      "grad_norm": 0.20418891310691833,
      "learning_rate": 1.086021505376344e-05,
      "loss": 0.0148,
      "step": 317
    },
    {
      "epoch": 2.0514883346741755,
      "grad_norm": 0.4264543056488037,
      "learning_rate": 1.0824372759856632e-05,
      "loss": 0.018,
      "step": 318
    },
    {
      "epoch": 2.0579243765084474,
      "grad_norm": 0.23796766996383667,
      "learning_rate": 1.0788530465949823e-05,
      "loss": 0.0198,
      "step": 319
    },
    {
      "epoch": 2.0643604183427193,
      "grad_norm": 0.6249572038650513,
      "learning_rate": 1.0752688172043012e-05,
      "loss": 0.1053,
      "step": 320
    },
    {
      "epoch": 2.0707964601769913,
      "grad_norm": 0.39948877692222595,
      "learning_rate": 1.0716845878136202e-05,
      "loss": 0.0161,
      "step": 321
    },
    {
      "epoch": 2.077232502011263,
      "grad_norm": 0.2628123462200165,
      "learning_rate": 1.0681003584229393e-05,
      "loss": 0.016,
      "step": 322
    },
    {
      "epoch": 2.083668543845535,
      "grad_norm": 0.36724066734313965,
      "learning_rate": 1.0645161290322582e-05,
      "loss": 0.019,
      "step": 323
    },
    {
      "epoch": 2.090104585679807,
      "grad_norm": 0.49291178584098816,
      "learning_rate": 1.0609318996415772e-05,
      "loss": 0.0932,
      "step": 324
    },
    {
      "epoch": 2.096540627514079,
      "grad_norm": 0.1628955602645874,
      "learning_rate": 1.0573476702508963e-05,
      "loss": 0.008,
      "step": 325
    },
    {
      "epoch": 2.102976669348351,
      "grad_norm": 0.24707062542438507,
      "learning_rate": 1.0537634408602151e-05,
      "loss": 0.0164,
      "step": 326
    },
    {
      "epoch": 2.109412711182623,
      "grad_norm": 0.12281152606010437,
      "learning_rate": 1.0501792114695342e-05,
      "loss": 0.0045,
      "step": 327
    },
    {
      "epoch": 2.115848753016895,
      "grad_norm": 0.12390667200088501,
      "learning_rate": 1.0465949820788533e-05,
      "loss": 0.0069,
      "step": 328
    },
    {
      "epoch": 2.1222847948511667,
      "grad_norm": 0.1263038069009781,
      "learning_rate": 1.0430107526881721e-05,
      "loss": 0.0046,
      "step": 329
    },
    {
      "epoch": 2.1287208366854387,
      "grad_norm": 0.2104724943637848,
      "learning_rate": 1.0394265232974912e-05,
      "loss": 0.0077,
      "step": 330
    },
    {
      "epoch": 2.1351568785197106,
      "grad_norm": 0.266082227230072,
      "learning_rate": 1.03584229390681e-05,
      "loss": 0.0249,
      "step": 331
    },
    {
      "epoch": 2.1415929203539825,
      "grad_norm": 0.50459885597229,
      "learning_rate": 1.0322580645161291e-05,
      "loss": 0.0338,
      "step": 332
    },
    {
      "epoch": 2.1480289621882545,
      "grad_norm": 0.19032877683639526,
      "learning_rate": 1.0286738351254482e-05,
      "loss": 0.0147,
      "step": 333
    },
    {
      "epoch": 2.154465004022526,
      "grad_norm": 0.27441638708114624,
      "learning_rate": 1.025089605734767e-05,
      "loss": 0.0151,
      "step": 334
    },
    {
      "epoch": 2.160901045856798,
      "grad_norm": 0.14048627018928528,
      "learning_rate": 1.0215053763440861e-05,
      "loss": 0.0145,
      "step": 335
    },
    {
      "epoch": 2.16733708769107,
      "grad_norm": 0.14861445128917694,
      "learning_rate": 1.0179211469534052e-05,
      "loss": 0.0053,
      "step": 336
    },
    {
      "epoch": 2.1737731295253417,
      "grad_norm": 0.18062621355056763,
      "learning_rate": 1.014336917562724e-05,
      "loss": 0.0211,
      "step": 337
    },
    {
      "epoch": 2.1802091713596137,
      "grad_norm": 0.26372599601745605,
      "learning_rate": 1.0107526881720431e-05,
      "loss": 0.0279,
      "step": 338
    },
    {
      "epoch": 2.1866452131938856,
      "grad_norm": 0.5490848422050476,
      "learning_rate": 1.0071684587813621e-05,
      "loss": 0.1035,
      "step": 339
    },
    {
      "epoch": 2.1930812550281575,
      "grad_norm": 0.8697487711906433,
      "learning_rate": 1.003584229390681e-05,
      "loss": 0.1336,
      "step": 340
    },
    {
      "epoch": 2.1995172968624295,
      "grad_norm": 0.5181514024734497,
      "learning_rate": 1e-05,
      "loss": 0.086,
      "step": 341
    },
    {
      "epoch": 2.2059533386967014,
      "grad_norm": 0.09736157953739166,
      "learning_rate": 9.96415770609319e-06,
      "loss": 0.0031,
      "step": 342
    },
    {
      "epoch": 2.2123893805309733,
      "grad_norm": 0.522585928440094,
      "learning_rate": 9.928315412186382e-06,
      "loss": 0.0962,
      "step": 343
    },
    {
      "epoch": 2.2188254223652453,
      "grad_norm": 0.260814905166626,
      "learning_rate": 9.89247311827957e-06,
      "loss": 0.012,
      "step": 344
    },
    {
      "epoch": 2.225261464199517,
      "grad_norm": 0.5897597670555115,
      "learning_rate": 9.856630824372761e-06,
      "loss": 0.1401,
      "step": 345
    },
    {
      "epoch": 2.231697506033789,
      "grad_norm": 0.548611581325531,
      "learning_rate": 9.820788530465952e-06,
      "loss": 0.0976,
      "step": 346
    },
    {
      "epoch": 2.238133547868061,
      "grad_norm": 0.3791581392288208,
      "learning_rate": 9.78494623655914e-06,
      "loss": 0.0913,
      "step": 347
    },
    {
      "epoch": 2.244569589702333,
      "grad_norm": 0.46227142214775085,
      "learning_rate": 9.749103942652331e-06,
      "loss": 0.0879,
      "step": 348
    },
    {
      "epoch": 2.251005631536605,
      "grad_norm": 0.49995407462120056,
      "learning_rate": 9.71326164874552e-06,
      "loss": 0.0936,
      "step": 349
    },
    {
      "epoch": 2.257441673370877,
      "grad_norm": 0.5805021524429321,
      "learning_rate": 9.67741935483871e-06,
      "loss": 0.113,
      "step": 350
    },
    {
      "epoch": 2.257441673370877,
      "eval_loss": 0.04894288629293442,
      "eval_runtime": 51.5193,
      "eval_samples_per_second": 24.127,
      "eval_steps_per_second": 1.514,
      "step": 350
    },
    {
      "epoch": 2.263877715205149,
      "grad_norm": 0.4636668264865875,
      "learning_rate": 9.641577060931901e-06,
      "loss": 0.0187,
      "step": 351
    },
    {
      "epoch": 2.2703137570394207,
      "grad_norm": 0.2844074070453644,
      "learning_rate": 9.60573476702509e-06,
      "loss": 0.0127,
      "step": 352
    },
    {
      "epoch": 2.2767497988736927,
      "grad_norm": 0.5263992547988892,
      "learning_rate": 9.56989247311828e-06,
      "loss": 0.1035,
      "step": 353
    },
    {
      "epoch": 2.2831858407079646,
      "grad_norm": 0.31317469477653503,
      "learning_rate": 9.53405017921147e-06,
      "loss": 0.0367,
      "step": 354
    },
    {
      "epoch": 2.2896218825422365,
      "grad_norm": 0.7165523767471313,
      "learning_rate": 9.49820788530466e-06,
      "loss": 0.1064,
      "step": 355
    },
    {
      "epoch": 2.2960579243765085,
      "grad_norm": 0.2489462047815323,
      "learning_rate": 9.46236559139785e-06,
      "loss": 0.0166,
      "step": 356
    },
    {
      "epoch": 2.3024939662107804,
      "grad_norm": 0.7237312197685242,
      "learning_rate": 9.42652329749104e-06,
      "loss": 0.0928,
      "step": 357
    },
    {
      "epoch": 2.3089300080450523,
      "grad_norm": 0.35997316241264343,
      "learning_rate": 9.39068100358423e-06,
      "loss": 0.0135,
      "step": 358
    },
    {
      "epoch": 2.3153660498793243,
      "grad_norm": 0.3035481870174408,
      "learning_rate": 9.35483870967742e-06,
      "loss": 0.0288,
      "step": 359
    },
    {
      "epoch": 2.321802091713596,
      "grad_norm": 0.31997376680374146,
      "learning_rate": 9.31899641577061e-06,
      "loss": 0.0086,
      "step": 360
    },
    {
      "epoch": 2.328238133547868,
      "grad_norm": 0.325218141078949,
      "learning_rate": 9.2831541218638e-06,
      "loss": 0.0353,
      "step": 361
    },
    {
      "epoch": 2.33467417538214,
      "grad_norm": 0.8689150214195251,
      "learning_rate": 9.24731182795699e-06,
      "loss": 0.1177,
      "step": 362
    },
    {
      "epoch": 2.341110217216412,
      "grad_norm": 0.302925705909729,
      "learning_rate": 9.21146953405018e-06,
      "loss": 0.0193,
      "step": 363
    },
    {
      "epoch": 2.347546259050684,
      "grad_norm": 0.3388362526893616,
      "learning_rate": 9.17562724014337e-06,
      "loss": 0.0082,
      "step": 364
    },
    {
      "epoch": 2.353982300884956,
      "grad_norm": 0.6252508759498596,
      "learning_rate": 9.13978494623656e-06,
      "loss": 0.0954,
      "step": 365
    },
    {
      "epoch": 2.360418342719228,
      "grad_norm": 0.19283771514892578,
      "learning_rate": 9.10394265232975e-06,
      "loss": 0.0131,
      "step": 366
    },
    {
      "epoch": 2.3668543845534997,
      "grad_norm": 0.2892359793186188,
      "learning_rate": 9.068100358422939e-06,
      "loss": 0.0324,
      "step": 367
    },
    {
      "epoch": 2.3732904263877717,
      "grad_norm": 0.5340448617935181,
      "learning_rate": 9.03225806451613e-06,
      "loss": 0.0198,
      "step": 368
    },
    {
      "epoch": 2.3797264682220436,
      "grad_norm": 0.13069525361061096,
      "learning_rate": 8.99641577060932e-06,
      "loss": 0.0104,
      "step": 369
    },
    {
      "epoch": 2.3861625100563155,
      "grad_norm": 0.5516209006309509,
      "learning_rate": 8.96057347670251e-06,
      "loss": 0.0259,
      "step": 370
    },
    {
      "epoch": 2.3925985518905875,
      "grad_norm": 0.24533021450042725,
      "learning_rate": 8.9247311827957e-06,
      "loss": 0.0274,
      "step": 371
    },
    {
      "epoch": 2.3990345937248594,
      "grad_norm": 0.3079507052898407,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.0215,
      "step": 372
    },
    {
      "epoch": 2.4054706355591313,
      "grad_norm": 0.33209100365638733,
      "learning_rate": 8.85304659498208e-06,
      "loss": 0.0162,
      "step": 373
    },
    {
      "epoch": 2.411906677393403,
      "grad_norm": 0.17269831895828247,
      "learning_rate": 8.81720430107527e-06,
      "loss": 0.02,
      "step": 374
    },
    {
      "epoch": 2.4183427192276747,
      "grad_norm": 0.09898678958415985,
      "learning_rate": 8.78136200716846e-06,
      "loss": 0.0021,
      "step": 375
    },
    {
      "epoch": 2.4247787610619467,
      "grad_norm": 0.22952893376350403,
      "learning_rate": 8.74551971326165e-06,
      "loss": 0.0344,
      "step": 376
    },
    {
      "epoch": 2.4312148028962186,
      "grad_norm": 2.356872320175171,
      "learning_rate": 8.70967741935484e-06,
      "loss": 0.3352,
      "step": 377
    },
    {
      "epoch": 2.4376508447304905,
      "grad_norm": 0.29283297061920166,
      "learning_rate": 8.67383512544803e-06,
      "loss": 0.0105,
      "step": 378
    },
    {
      "epoch": 2.4440868865647625,
      "grad_norm": 0.8146191835403442,
      "learning_rate": 8.63799283154122e-06,
      "loss": 0.1014,
      "step": 379
    },
    {
      "epoch": 2.4505229283990344,
      "grad_norm": 0.23613350093364716,
      "learning_rate": 8.602150537634409e-06,
      "loss": 0.0135,
      "step": 380
    },
    {
      "epoch": 2.4569589702333063,
      "grad_norm": 0.18557389080524445,
      "learning_rate": 8.5663082437276e-06,
      "loss": 0.0125,
      "step": 381
    },
    {
      "epoch": 2.4633950120675783,
      "grad_norm": 0.6450138688087463,
      "learning_rate": 8.530465949820788e-06,
      "loss": 0.0305,
      "step": 382
    },
    {
      "epoch": 2.46983105390185,
      "grad_norm": 0.1474761664867401,
      "learning_rate": 8.494623655913979e-06,
      "loss": 0.0174,
      "step": 383
    },
    {
      "epoch": 2.476267095736122,
      "grad_norm": 0.4506015181541443,
      "learning_rate": 8.45878136200717e-06,
      "loss": 0.028,
      "step": 384
    },
    {
      "epoch": 2.482703137570394,
      "grad_norm": 0.6606436967849731,
      "learning_rate": 8.422939068100358e-06,
      "loss": 0.0983,
      "step": 385
    },
    {
      "epoch": 2.489139179404666,
      "grad_norm": 0.5096504092216492,
      "learning_rate": 8.387096774193549e-06,
      "loss": 0.0861,
      "step": 386
    },
    {
      "epoch": 2.495575221238938,
      "grad_norm": 0.24929137527942657,
      "learning_rate": 8.35125448028674e-06,
      "loss": 0.0152,
      "step": 387
    },
    {
      "epoch": 2.50201126307321,
      "grad_norm": 0.26318851113319397,
      "learning_rate": 8.315412186379928e-06,
      "loss": 0.0157,
      "step": 388
    },
    {
      "epoch": 2.508447304907482,
      "grad_norm": 0.35995998978614807,
      "learning_rate": 8.279569892473119e-06,
      "loss": 0.0795,
      "step": 389
    },
    {
      "epoch": 2.5148833467417537,
      "grad_norm": 0.5183810591697693,
      "learning_rate": 8.24372759856631e-06,
      "loss": 0.0848,
      "step": 390
    },
    {
      "epoch": 2.5213193885760257,
      "grad_norm": 0.8360742330551147,
      "learning_rate": 8.207885304659498e-06,
      "loss": 0.1075,
      "step": 391
    },
    {
      "epoch": 2.5277554304102976,
      "grad_norm": 0.2811218798160553,
      "learning_rate": 8.172043010752689e-06,
      "loss": 0.0194,
      "step": 392
    },
    {
      "epoch": 2.5341914722445695,
      "grad_norm": 0.44018790125846863,
      "learning_rate": 8.136200716845879e-06,
      "loss": 0.0922,
      "step": 393
    },
    {
      "epoch": 2.5406275140788415,
      "grad_norm": 0.1854783445596695,
      "learning_rate": 8.100358422939068e-06,
      "loss": 0.008,
      "step": 394
    },
    {
      "epoch": 2.5470635559131134,
      "grad_norm": 0.18530158698558807,
      "learning_rate": 8.064516129032258e-06,
      "loss": 0.0333,
      "step": 395
    },
    {
      "epoch": 2.5534995977473853,
      "grad_norm": 1.5239174365997314,
      "learning_rate": 8.028673835125449e-06,
      "loss": 0.2008,
      "step": 396
    },
    {
      "epoch": 2.5599356395816573,
      "grad_norm": 0.2239239513874054,
      "learning_rate": 7.992831541218638e-06,
      "loss": 0.0235,
      "step": 397
    },
    {
      "epoch": 2.566371681415929,
      "grad_norm": 0.7383996248245239,
      "learning_rate": 7.956989247311828e-06,
      "loss": 0.0325,
      "step": 398
    },
    {
      "epoch": 2.572807723250201,
      "grad_norm": 0.48525378108024597,
      "learning_rate": 7.921146953405019e-06,
      "loss": 0.0254,
      "step": 399
    },
    {
      "epoch": 2.579243765084473,
      "grad_norm": 0.1645464152097702,
      "learning_rate": 7.88530465949821e-06,
      "loss": 0.0074,
      "step": 400
    },
    {
      "epoch": 2.579243765084473,
      "eval_loss": 0.046789053827524185,
      "eval_runtime": 51.4367,
      "eval_samples_per_second": 24.166,
      "eval_steps_per_second": 1.516,
      "step": 400
    },
    {
      "epoch": 2.585679806918745,
      "grad_norm": 0.2009619176387787,
      "learning_rate": 7.849462365591398e-06,
      "loss": 0.0126,
      "step": 401
    },
    {
      "epoch": 2.592115848753017,
      "grad_norm": 0.1853858381509781,
      "learning_rate": 7.813620071684589e-06,
      "loss": 0.0086,
      "step": 402
    },
    {
      "epoch": 2.598551890587289,
      "grad_norm": 0.5341307520866394,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.0186,
      "step": 403
    },
    {
      "epoch": 2.604987932421561,
      "grad_norm": 0.13335858285427094,
      "learning_rate": 7.741935483870968e-06,
      "loss": 0.0116,
      "step": 404
    },
    {
      "epoch": 2.6114239742558327,
      "grad_norm": 0.37012988328933716,
      "learning_rate": 7.706093189964159e-06,
      "loss": 0.0266,
      "step": 405
    },
    {
      "epoch": 2.6178600160901047,
      "grad_norm": 0.7409452199935913,
      "learning_rate": 7.670250896057349e-06,
      "loss": 0.0982,
      "step": 406
    },
    {
      "epoch": 2.6242960579243766,
      "grad_norm": 0.5900397300720215,
      "learning_rate": 7.634408602150538e-06,
      "loss": 0.1038,
      "step": 407
    },
    {
      "epoch": 2.6307320997586485,
      "grad_norm": 0.6353976130485535,
      "learning_rate": 7.5985663082437275e-06,
      "loss": 0.1848,
      "step": 408
    },
    {
      "epoch": 2.6371681415929205,
      "grad_norm": 0.23982127010822296,
      "learning_rate": 7.562724014336919e-06,
      "loss": 0.0154,
      "step": 409
    },
    {
      "epoch": 2.6436041834271924,
      "grad_norm": 0.26363855600357056,
      "learning_rate": 7.526881720430108e-06,
      "loss": 0.0207,
      "step": 410
    },
    {
      "epoch": 2.6500402252614643,
      "grad_norm": 0.190507173538208,
      "learning_rate": 7.491039426523297e-06,
      "loss": 0.0154,
      "step": 411
    },
    {
      "epoch": 2.6564762670957363,
      "grad_norm": 0.3038678467273712,
      "learning_rate": 7.455197132616489e-06,
      "loss": 0.0076,
      "step": 412
    },
    {
      "epoch": 2.662912308930008,
      "grad_norm": 0.6025294661521912,
      "learning_rate": 7.4193548387096784e-06,
      "loss": 0.1034,
      "step": 413
    },
    {
      "epoch": 2.66934835076428,
      "grad_norm": 1.7746405601501465,
      "learning_rate": 7.383512544802868e-06,
      "loss": 0.3065,
      "step": 414
    },
    {
      "epoch": 2.675784392598552,
      "grad_norm": 0.5126484036445618,
      "learning_rate": 7.347670250896059e-06,
      "loss": 0.0803,
      "step": 415
    },
    {
      "epoch": 2.682220434432824,
      "grad_norm": 0.3284212052822113,
      "learning_rate": 7.311827956989248e-06,
      "loss": 0.0233,
      "step": 416
    },
    {
      "epoch": 2.688656476267096,
      "grad_norm": 0.5528810024261475,
      "learning_rate": 7.275985663082438e-06,
      "loss": 0.1002,
      "step": 417
    },
    {
      "epoch": 2.695092518101368,
      "grad_norm": 0.6601383090019226,
      "learning_rate": 7.240143369175628e-06,
      "loss": 0.1122,
      "step": 418
    },
    {
      "epoch": 2.70152855993564,
      "grad_norm": 0.6489747762680054,
      "learning_rate": 7.204301075268818e-06,
      "loss": 0.106,
      "step": 419
    },
    {
      "epoch": 2.7079646017699117,
      "grad_norm": 0.5583483576774597,
      "learning_rate": 7.168458781362008e-06,
      "loss": 0.1075,
      "step": 420
    },
    {
      "epoch": 2.7144006436041836,
      "grad_norm": 0.28439822793006897,
      "learning_rate": 7.1326164874551975e-06,
      "loss": 0.0104,
      "step": 421
    },
    {
      "epoch": 2.7208366854384556,
      "grad_norm": 0.3614722490310669,
      "learning_rate": 7.096774193548388e-06,
      "loss": 0.0825,
      "step": 422
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.35983020067214966,
      "learning_rate": 7.060931899641578e-06,
      "loss": 0.0259,
      "step": 423
    },
    {
      "epoch": 2.7337087691069994,
      "grad_norm": 0.1344391256570816,
      "learning_rate": 7.025089605734767e-06,
      "loss": 0.0064,
      "step": 424
    },
    {
      "epoch": 2.7401448109412714,
      "grad_norm": 0.27596011757850647,
      "learning_rate": 6.989247311827958e-06,
      "loss": 0.0239,
      "step": 425
    },
    {
      "epoch": 2.7465808527755433,
      "grad_norm": 0.3379741907119751,
      "learning_rate": 6.9534050179211476e-06,
      "loss": 0.0161,
      "step": 426
    },
    {
      "epoch": 2.753016894609815,
      "grad_norm": 0.2865120470523834,
      "learning_rate": 6.917562724014337e-06,
      "loss": 0.0284,
      "step": 427
    },
    {
      "epoch": 2.7594529364440867,
      "grad_norm": 0.28130829334259033,
      "learning_rate": 6.881720430107528e-06,
      "loss": 0.0111,
      "step": 428
    },
    {
      "epoch": 2.7658889782783587,
      "grad_norm": 0.4515400528907776,
      "learning_rate": 6.8458781362007174e-06,
      "loss": 0.0879,
      "step": 429
    },
    {
      "epoch": 2.7723250201126306,
      "grad_norm": 0.29504266381263733,
      "learning_rate": 6.810035842293907e-06,
      "loss": 0.0268,
      "step": 430
    },
    {
      "epoch": 2.7787610619469025,
      "grad_norm": 0.6445298790931702,
      "learning_rate": 6.774193548387097e-06,
      "loss": 0.0321,
      "step": 431
    },
    {
      "epoch": 2.7851971037811745,
      "grad_norm": 0.1848435252904892,
      "learning_rate": 6.738351254480287e-06,
      "loss": 0.0116,
      "step": 432
    },
    {
      "epoch": 2.7916331456154464,
      "grad_norm": 0.4086310863494873,
      "learning_rate": 6.702508960573477e-06,
      "loss": 0.0128,
      "step": 433
    },
    {
      "epoch": 2.7980691874497183,
      "grad_norm": 0.21758578717708588,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.0063,
      "step": 434
    },
    {
      "epoch": 2.8045052292839903,
      "grad_norm": 0.22773584723472595,
      "learning_rate": 6.630824372759857e-06,
      "loss": 0.0127,
      "step": 435
    },
    {
      "epoch": 2.810941271118262,
      "grad_norm": 0.19627118110656738,
      "learning_rate": 6.594982078853047e-06,
      "loss": 0.0171,
      "step": 436
    },
    {
      "epoch": 2.817377312952534,
      "grad_norm": 0.40931466221809387,
      "learning_rate": 6.5591397849462365e-06,
      "loss": 0.0231,
      "step": 437
    },
    {
      "epoch": 2.823813354786806,
      "grad_norm": 0.2828005254268646,
      "learning_rate": 6.523297491039428e-06,
      "loss": 0.008,
      "step": 438
    },
    {
      "epoch": 2.830249396621078,
      "grad_norm": 0.4745807647705078,
      "learning_rate": 6.4874551971326176e-06,
      "loss": 0.02,
      "step": 439
    },
    {
      "epoch": 2.83668543845535,
      "grad_norm": 0.17342859506607056,
      "learning_rate": 6.451612903225806e-06,
      "loss": 0.016,
      "step": 440
    },
    {
      "epoch": 2.843121480289622,
      "grad_norm": 0.796079695224762,
      "learning_rate": 6.415770609318996e-06,
      "loss": 0.0451,
      "step": 441
    },
    {
      "epoch": 2.849557522123894,
      "grad_norm": 0.255141019821167,
      "learning_rate": 6.379928315412187e-06,
      "loss": 0.0186,
      "step": 442
    },
    {
      "epoch": 2.8559935639581657,
      "grad_norm": 0.20012632012367249,
      "learning_rate": 6.344086021505377e-06,
      "loss": 0.0148,
      "step": 443
    },
    {
      "epoch": 2.8624296057924377,
      "grad_norm": 0.6595253348350525,
      "learning_rate": 6.308243727598567e-06,
      "loss": 0.0854,
      "step": 444
    },
    {
      "epoch": 2.8688656476267096,
      "grad_norm": 0.25864025950431824,
      "learning_rate": 6.272401433691757e-06,
      "loss": 0.0074,
      "step": 445
    },
    {
      "epoch": 2.8753016894609815,
      "grad_norm": 0.7931526303291321,
      "learning_rate": 6.236559139784947e-06,
      "loss": 0.1674,
      "step": 446
    },
    {
      "epoch": 2.8817377312952535,
      "grad_norm": 0.22236619889736176,
      "learning_rate": 6.200716845878137e-06,
      "loss": 0.0053,
      "step": 447
    },
    {
      "epoch": 2.8881737731295254,
      "grad_norm": 0.4570053517818451,
      "learning_rate": 6.164874551971327e-06,
      "loss": 0.09,
      "step": 448
    },
    {
      "epoch": 2.8946098149637973,
      "grad_norm": 0.4497288763523102,
      "learning_rate": 6.129032258064517e-06,
      "loss": 0.0409,
      "step": 449
    },
    {
      "epoch": 2.9010458567980693,
      "grad_norm": 0.22530314326286316,
      "learning_rate": 6.0931899641577065e-06,
      "loss": 0.0279,
      "step": 450
    },
    {
      "epoch": 2.9010458567980693,
      "eval_loss": 0.04714740440249443,
      "eval_runtime": 51.7997,
      "eval_samples_per_second": 23.996,
      "eval_steps_per_second": 1.506,
      "step": 450
    },
    {
      "epoch": 2.907481898632341,
      "grad_norm": 0.5039365887641907,
      "learning_rate": 6.057347670250897e-06,
      "loss": 0.019,
      "step": 451
    },
    {
      "epoch": 2.913917940466613,
      "grad_norm": 0.5053332448005676,
      "learning_rate": 6.021505376344087e-06,
      "loss": 0.0225,
      "step": 452
    },
    {
      "epoch": 2.920353982300885,
      "grad_norm": 0.3723827600479126,
      "learning_rate": 5.985663082437276e-06,
      "loss": 0.0197,
      "step": 453
    },
    {
      "epoch": 2.926790024135157,
      "grad_norm": 0.6789116263389587,
      "learning_rate": 5.949820788530466e-06,
      "loss": 0.0293,
      "step": 454
    },
    {
      "epoch": 2.933226065969429,
      "grad_norm": 0.17943812906742096,
      "learning_rate": 5.9139784946236566e-06,
      "loss": 0.0143,
      "step": 455
    },
    {
      "epoch": 2.939662107803701,
      "grad_norm": 0.6598175764083862,
      "learning_rate": 5.878136200716846e-06,
      "loss": 0.0365,
      "step": 456
    },
    {
      "epoch": 2.946098149637973,
      "grad_norm": 0.15531907975673676,
      "learning_rate": 5.842293906810036e-06,
      "loss": 0.0104,
      "step": 457
    },
    {
      "epoch": 2.9525341914722447,
      "grad_norm": 0.6269444227218628,
      "learning_rate": 5.806451612903226e-06,
      "loss": 0.1014,
      "step": 458
    },
    {
      "epoch": 2.9589702333065167,
      "grad_norm": 0.3285280764102936,
      "learning_rate": 5.770609318996416e-06,
      "loss": 0.0106,
      "step": 459
    },
    {
      "epoch": 2.965406275140788,
      "grad_norm": 0.19270984828472137,
      "learning_rate": 5.734767025089606e-06,
      "loss": 0.0196,
      "step": 460
    },
    {
      "epoch": 2.97184231697506,
      "grad_norm": 0.33533531427383423,
      "learning_rate": 5.698924731182796e-06,
      "loss": 0.029,
      "step": 461
    },
    {
      "epoch": 2.978278358809332,
      "grad_norm": 0.7429119348526001,
      "learning_rate": 5.663082437275986e-06,
      "loss": 0.1177,
      "step": 462
    },
    {
      "epoch": 2.984714400643604,
      "grad_norm": 0.1719256192445755,
      "learning_rate": 5.627240143369176e-06,
      "loss": 0.0076,
      "step": 463
    },
    {
      "epoch": 2.991150442477876,
      "grad_norm": 0.4622393548488617,
      "learning_rate": 5.591397849462365e-06,
      "loss": 0.0486,
      "step": 464
    },
    {
      "epoch": 2.997586484312148,
      "grad_norm": 0.3571280539035797,
      "learning_rate": 5.555555555555557e-06,
      "loss": 0.0299,
      "step": 465
    },
    {
      "epoch": 3.006436041834272,
      "grad_norm": 4.171768665313721,
      "learning_rate": 5.5197132616487455e-06,
      "loss": 0.6769,
      "step": 466
    },
    {
      "epoch": 3.012872083668544,
      "grad_norm": 0.16829149425029755,
      "learning_rate": 5.483870967741935e-06,
      "loss": 0.0143,
      "step": 467
    },
    {
      "epoch": 3.019308125502816,
      "grad_norm": 0.145945206284523,
      "learning_rate": 5.4480286738351265e-06,
      "loss": 0.0175,
      "step": 468
    },
    {
      "epoch": 3.0257441673370877,
      "grad_norm": 0.4693124294281006,
      "learning_rate": 5.412186379928316e-06,
      "loss": 0.085,
      "step": 469
    },
    {
      "epoch": 3.0321802091713597,
      "grad_norm": 0.2549896836280823,
      "learning_rate": 5.376344086021506e-06,
      "loss": 0.0139,
      "step": 470
    },
    {
      "epoch": 3.0386162510056316,
      "grad_norm": 0.32817843556404114,
      "learning_rate": 5.340501792114696e-06,
      "loss": 0.0172,
      "step": 471
    },
    {
      "epoch": 3.0450522928399035,
      "grad_norm": 0.27429020404815674,
      "learning_rate": 5.304659498207886e-06,
      "loss": 0.0351,
      "step": 472
    },
    {
      "epoch": 3.0514883346741755,
      "grad_norm": 0.2382006049156189,
      "learning_rate": 5.268817204301076e-06,
      "loss": 0.0131,
      "step": 473
    },
    {
      "epoch": 3.0579243765084474,
      "grad_norm": 0.2107856571674347,
      "learning_rate": 5.232974910394266e-06,
      "loss": 0.0146,
      "step": 474
    },
    {
      "epoch": 3.0643604183427193,
      "grad_norm": 0.46777406334877014,
      "learning_rate": 5.197132616487456e-06,
      "loss": 0.087,
      "step": 475
    },
    {
      "epoch": 3.0707964601769913,
      "grad_norm": 0.6037535071372986,
      "learning_rate": 5.161290322580646e-06,
      "loss": 0.0925,
      "step": 476
    },
    {
      "epoch": 3.077232502011263,
      "grad_norm": 0.17324893176555634,
      "learning_rate": 5.125448028673835e-06,
      "loss": 0.0052,
      "step": 477
    },
    {
      "epoch": 3.083668543845535,
      "grad_norm": 0.30920279026031494,
      "learning_rate": 5.089605734767026e-06,
      "loss": 0.0197,
      "step": 478
    },
    {
      "epoch": 3.090104585679807,
      "grad_norm": 0.1764673888683319,
      "learning_rate": 5.0537634408602155e-06,
      "loss": 0.0154,
      "step": 479
    },
    {
      "epoch": 3.096540627514079,
      "grad_norm": 0.4834371507167816,
      "learning_rate": 5.017921146953405e-06,
      "loss": 0.0861,
      "step": 480
    },
    {
      "epoch": 3.102976669348351,
      "grad_norm": 0.1595529317855835,
      "learning_rate": 4.982078853046595e-06,
      "loss": 0.017,
      "step": 481
    },
    {
      "epoch": 3.109412711182623,
      "grad_norm": 0.22436025738716125,
      "learning_rate": 4.946236559139785e-06,
      "loss": 0.0155,
      "step": 482
    },
    {
      "epoch": 3.115848753016895,
      "grad_norm": 0.21622468531131744,
      "learning_rate": 4.910394265232976e-06,
      "loss": 0.0249,
      "step": 483
    },
    {
      "epoch": 3.1222847948511667,
      "grad_norm": 0.33063796162605286,
      "learning_rate": 4.8745519713261655e-06,
      "loss": 0.0123,
      "step": 484
    },
    {
      "epoch": 3.1287208366854387,
      "grad_norm": 0.6433096528053284,
      "learning_rate": 4.838709677419355e-06,
      "loss": 0.0883,
      "step": 485
    },
    {
      "epoch": 3.1351568785197106,
      "grad_norm": 0.19802157580852509,
      "learning_rate": 4.802867383512545e-06,
      "loss": 0.0223,
      "step": 486
    },
    {
      "epoch": 3.1415929203539825,
      "grad_norm": 0.7198513746261597,
      "learning_rate": 4.767025089605735e-06,
      "loss": 0.178,
      "step": 487
    },
    {
      "epoch": 3.1480289621882545,
      "grad_norm": 0.5033941268920898,
      "learning_rate": 4.731182795698925e-06,
      "loss": 0.0324,
      "step": 488
    },
    {
      "epoch": 3.154465004022526,
      "grad_norm": 0.39918386936187744,
      "learning_rate": 4.695340501792115e-06,
      "loss": 0.016,
      "step": 489
    },
    {
      "epoch": 3.160901045856798,
      "grad_norm": 0.32294130325317383,
      "learning_rate": 4.659498207885305e-06,
      "loss": 0.0201,
      "step": 490
    },
    {
      "epoch": 3.16733708769107,
      "grad_norm": 0.22495481371879578,
      "learning_rate": 4.623655913978495e-06,
      "loss": 0.0059,
      "step": 491
    },
    {
      "epoch": 3.1737731295253417,
      "grad_norm": 0.3699261248111725,
      "learning_rate": 4.587813620071685e-06,
      "loss": 0.0192,
      "step": 492
    },
    {
      "epoch": 3.1802091713596137,
      "grad_norm": 0.5514989495277405,
      "learning_rate": 4.551971326164875e-06,
      "loss": 0.0965,
      "step": 493
    },
    {
      "epoch": 3.1866452131938856,
      "grad_norm": 0.6093651652336121,
      "learning_rate": 4.516129032258065e-06,
      "loss": 0.1571,
      "step": 494
    },
    {
      "epoch": 3.1930812550281575,
      "grad_norm": 0.7854407429695129,
      "learning_rate": 4.480286738351255e-06,
      "loss": 0.1567,
      "step": 495
    },
    {
      "epoch": 3.1995172968624295,
      "grad_norm": 0.1979871392250061,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.0083,
      "step": 496
    },
    {
      "epoch": 3.2059533386967014,
      "grad_norm": 0.500344455242157,
      "learning_rate": 4.408602150537635e-06,
      "loss": 0.0281,
      "step": 497
    },
    {
      "epoch": 3.2123893805309733,
      "grad_norm": 0.2444169670343399,
      "learning_rate": 4.372759856630825e-06,
      "loss": 0.0093,
      "step": 498
    },
    {
      "epoch": 3.2188254223652453,
      "grad_norm": 0.41572651267051697,
      "learning_rate": 4.336917562724015e-06,
      "loss": 0.0214,
      "step": 499
    },
    {
      "epoch": 3.225261464199517,
      "grad_norm": 0.4200991690158844,
      "learning_rate": 4.3010752688172045e-06,
      "loss": 0.0118,
      "step": 500
    },
    {
      "epoch": 3.225261464199517,
      "eval_loss": 0.04694278910756111,
      "eval_runtime": 51.4296,
      "eval_samples_per_second": 24.169,
      "eval_steps_per_second": 1.517,
      "step": 500
    },
    {
      "epoch": 3.231697506033789,
      "grad_norm": 0.9470365047454834,
      "learning_rate": 4.265232974910394e-06,
      "loss": 0.0541,
      "step": 501
    },
    {
      "epoch": 3.238133547868061,
      "grad_norm": 0.19459319114685059,
      "learning_rate": 4.229390681003585e-06,
      "loss": 0.0079,
      "step": 502
    },
    {
      "epoch": 3.244569589702333,
      "grad_norm": 0.29874229431152344,
      "learning_rate": 4.193548387096774e-06,
      "loss": 0.0187,
      "step": 503
    },
    {
      "epoch": 3.251005631536605,
      "grad_norm": 0.1895247995853424,
      "learning_rate": 4.157706093189964e-06,
      "loss": 0.0213,
      "step": 504
    },
    {
      "epoch": 3.257441673370877,
      "grad_norm": 0.36637061834335327,
      "learning_rate": 4.121863799283155e-06,
      "loss": 0.0171,
      "step": 505
    },
    {
      "epoch": 3.263877715205149,
      "grad_norm": 0.5156010389328003,
      "learning_rate": 4.086021505376344e-06,
      "loss": 0.0866,
      "step": 506
    },
    {
      "epoch": 3.2703137570394207,
      "grad_norm": 0.2930610477924347,
      "learning_rate": 4.050179211469534e-06,
      "loss": 0.03,
      "step": 507
    },
    {
      "epoch": 3.2767497988736927,
      "grad_norm": 0.36617934703826904,
      "learning_rate": 4.0143369175627245e-06,
      "loss": 0.0226,
      "step": 508
    },
    {
      "epoch": 3.2831858407079646,
      "grad_norm": 0.43050259351730347,
      "learning_rate": 3.978494623655914e-06,
      "loss": 0.0808,
      "step": 509
    },
    {
      "epoch": 3.2896218825422365,
      "grad_norm": 0.27476346492767334,
      "learning_rate": 3.942652329749105e-06,
      "loss": 0.0296,
      "step": 510
    },
    {
      "epoch": 3.2960579243765085,
      "grad_norm": 0.3111196458339691,
      "learning_rate": 3.906810035842294e-06,
      "loss": 0.0184,
      "step": 511
    },
    {
      "epoch": 3.3024939662107804,
      "grad_norm": 0.2161393165588379,
      "learning_rate": 3.870967741935484e-06,
      "loss": 0.0179,
      "step": 512
    },
    {
      "epoch": 3.3089300080450523,
      "grad_norm": 0.8398222923278809,
      "learning_rate": 3.8351254480286745e-06,
      "loss": 0.1703,
      "step": 513
    },
    {
      "epoch": 3.3153660498793243,
      "grad_norm": 0.6233034133911133,
      "learning_rate": 3.7992831541218638e-06,
      "loss": 0.0357,
      "step": 514
    },
    {
      "epoch": 3.321802091713596,
      "grad_norm": 0.5032597780227661,
      "learning_rate": 3.763440860215054e-06,
      "loss": 0.0902,
      "step": 515
    },
    {
      "epoch": 3.328238133547868,
      "grad_norm": 0.31081482768058777,
      "learning_rate": 3.7275985663082444e-06,
      "loss": 0.0108,
      "step": 516
    },
    {
      "epoch": 3.33467417538214,
      "grad_norm": 0.20317743718624115,
      "learning_rate": 3.691756272401434e-06,
      "loss": 0.0083,
      "step": 517
    },
    {
      "epoch": 3.341110217216412,
      "grad_norm": 0.3946802318096161,
      "learning_rate": 3.655913978494624e-06,
      "loss": 0.0386,
      "step": 518
    },
    {
      "epoch": 3.347546259050684,
      "grad_norm": 0.16467778384685516,
      "learning_rate": 3.620071684587814e-06,
      "loss": 0.0112,
      "step": 519
    },
    {
      "epoch": 3.353982300884956,
      "grad_norm": 0.24470770359039307,
      "learning_rate": 3.584229390681004e-06,
      "loss": 0.0272,
      "step": 520
    },
    {
      "epoch": 3.360418342719228,
      "grad_norm": 0.2137192189693451,
      "learning_rate": 3.548387096774194e-06,
      "loss": 0.0232,
      "step": 521
    },
    {
      "epoch": 3.3668543845534997,
      "grad_norm": 0.47849053144454956,
      "learning_rate": 3.5125448028673837e-06,
      "loss": 0.0517,
      "step": 522
    },
    {
      "epoch": 3.3732904263877717,
      "grad_norm": 0.6663035750389099,
      "learning_rate": 3.4767025089605738e-06,
      "loss": 0.1614,
      "step": 523
    },
    {
      "epoch": 3.3797264682220436,
      "grad_norm": 0.5238935351371765,
      "learning_rate": 3.440860215053764e-06,
      "loss": 0.0232,
      "step": 524
    },
    {
      "epoch": 3.3861625100563155,
      "grad_norm": 0.33285027742385864,
      "learning_rate": 3.4050179211469536e-06,
      "loss": 0.0127,
      "step": 525
    },
    {
      "epoch": 3.3925985518905875,
      "grad_norm": 0.36829882860183716,
      "learning_rate": 3.3691756272401437e-06,
      "loss": 0.0187,
      "step": 526
    },
    {
      "epoch": 3.3990345937248594,
      "grad_norm": 0.4461071491241455,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.03,
      "step": 527
    },
    {
      "epoch": 3.4054706355591313,
      "grad_norm": 0.32160046696662903,
      "learning_rate": 3.2974910394265234e-06,
      "loss": 0.0109,
      "step": 528
    },
    {
      "epoch": 3.411906677393403,
      "grad_norm": 0.32810530066490173,
      "learning_rate": 3.261648745519714e-06,
      "loss": 0.0147,
      "step": 529
    },
    {
      "epoch": 3.4183427192276747,
      "grad_norm": 0.30904990434646606,
      "learning_rate": 3.225806451612903e-06,
      "loss": 0.0135,
      "step": 530
    },
    {
      "epoch": 3.4247787610619467,
      "grad_norm": 0.10069498419761658,
      "learning_rate": 3.1899641577060937e-06,
      "loss": 0.0035,
      "step": 531
    },
    {
      "epoch": 3.4312148028962186,
      "grad_norm": 0.1542118340730667,
      "learning_rate": 3.1541218637992834e-06,
      "loss": 0.0075,
      "step": 532
    },
    {
      "epoch": 3.4376508447304905,
      "grad_norm": 0.5877416729927063,
      "learning_rate": 3.1182795698924735e-06,
      "loss": 0.0844,
      "step": 533
    },
    {
      "epoch": 3.4440868865647625,
      "grad_norm": 0.5212598443031311,
      "learning_rate": 3.0824372759856636e-06,
      "loss": 0.092,
      "step": 534
    },
    {
      "epoch": 3.4505229283990344,
      "grad_norm": 0.5427677035331726,
      "learning_rate": 3.0465949820788532e-06,
      "loss": 0.0251,
      "step": 535
    },
    {
      "epoch": 3.4569589702333063,
      "grad_norm": 0.1259840726852417,
      "learning_rate": 3.0107526881720433e-06,
      "loss": 0.011,
      "step": 536
    },
    {
      "epoch": 3.4633950120675783,
      "grad_norm": 0.652903139591217,
      "learning_rate": 2.974910394265233e-06,
      "loss": 0.0918,
      "step": 537
    },
    {
      "epoch": 3.46983105390185,
      "grad_norm": 0.18021413683891296,
      "learning_rate": 2.939068100358423e-06,
      "loss": 0.0053,
      "step": 538
    },
    {
      "epoch": 3.476267095736122,
      "grad_norm": 0.8723411560058594,
      "learning_rate": 2.903225806451613e-06,
      "loss": 0.0275,
      "step": 539
    },
    {
      "epoch": 3.482703137570394,
      "grad_norm": 0.21147771179676056,
      "learning_rate": 2.867383512544803e-06,
      "loss": 0.0155,
      "step": 540
    },
    {
      "epoch": 3.489139179404666,
      "grad_norm": 0.2786853313446045,
      "learning_rate": 2.831541218637993e-06,
      "loss": 0.0128,
      "step": 541
    },
    {
      "epoch": 3.495575221238938,
      "grad_norm": 0.47619229555130005,
      "learning_rate": 2.7956989247311827e-06,
      "loss": 0.0801,
      "step": 542
    },
    {
      "epoch": 3.50201126307321,
      "grad_norm": 0.7718125581741333,
      "learning_rate": 2.7598566308243727e-06,
      "loss": 0.158,
      "step": 543
    },
    {
      "epoch": 3.508447304907482,
      "grad_norm": 0.3480500280857086,
      "learning_rate": 2.7240143369175633e-06,
      "loss": 0.012,
      "step": 544
    },
    {
      "epoch": 3.5148833467417537,
      "grad_norm": 0.5632939338684082,
      "learning_rate": 2.688172043010753e-06,
      "loss": 0.0251,
      "step": 545
    },
    {
      "epoch": 3.5213193885760257,
      "grad_norm": 0.18412992358207703,
      "learning_rate": 2.652329749103943e-06,
      "loss": 0.0116,
      "step": 546
    },
    {
      "epoch": 3.5277554304102976,
      "grad_norm": 1.8919442892074585,
      "learning_rate": 2.616487455197133e-06,
      "loss": 0.2376,
      "step": 547
    },
    {
      "epoch": 3.5341914722445695,
      "grad_norm": 0.16928070783615112,
      "learning_rate": 2.580645161290323e-06,
      "loss": 0.005,
      "step": 548
    },
    {
      "epoch": 3.5406275140788415,
      "grad_norm": 0.16667534410953522,
      "learning_rate": 2.544802867383513e-06,
      "loss": 0.0159,
      "step": 549
    },
    {
      "epoch": 3.5470635559131134,
      "grad_norm": 0.5230170488357544,
      "learning_rate": 2.5089605734767026e-06,
      "loss": 0.1024,
      "step": 550
    },
    {
      "epoch": 3.5470635559131134,
      "eval_loss": 0.04525020718574524,
      "eval_runtime": 51.4891,
      "eval_samples_per_second": 24.141,
      "eval_steps_per_second": 1.515,
      "step": 550
    },
    {
      "epoch": 3.5534995977473853,
      "grad_norm": 0.41775500774383545,
      "learning_rate": 2.4731182795698927e-06,
      "loss": 0.0738,
      "step": 551
    },
    {
      "epoch": 3.5599356395816573,
      "grad_norm": 0.4451899528503418,
      "learning_rate": 2.4372759856630828e-06,
      "loss": 0.0745,
      "step": 552
    },
    {
      "epoch": 3.566371681415929,
      "grad_norm": 0.2577010989189148,
      "learning_rate": 2.4014336917562724e-06,
      "loss": 0.0185,
      "step": 553
    },
    {
      "epoch": 3.572807723250201,
      "grad_norm": 0.40455350279808044,
      "learning_rate": 2.3655913978494625e-06,
      "loss": 0.0779,
      "step": 554
    },
    {
      "epoch": 3.579243765084473,
      "grad_norm": 0.8852919936180115,
      "learning_rate": 2.3297491039426526e-06,
      "loss": 0.2325,
      "step": 555
    },
    {
      "epoch": 3.585679806918745,
      "grad_norm": 0.5969845652580261,
      "learning_rate": 2.2939068100358423e-06,
      "loss": 0.0914,
      "step": 556
    },
    {
      "epoch": 3.592115848753017,
      "grad_norm": 0.4391111731529236,
      "learning_rate": 2.2580645161290324e-06,
      "loss": 0.022,
      "step": 557
    },
    {
      "epoch": 3.598551890587289,
      "grad_norm": 0.11725497245788574,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.0064,
      "step": 558
    },
    {
      "epoch": 3.604987932421561,
      "grad_norm": 0.3035472333431244,
      "learning_rate": 2.1863799283154126e-06,
      "loss": 0.0204,
      "step": 559
    },
    {
      "epoch": 3.6114239742558327,
      "grad_norm": 0.5796228647232056,
      "learning_rate": 2.1505376344086023e-06,
      "loss": 0.1078,
      "step": 560
    },
    {
      "epoch": 3.6178600160901047,
      "grad_norm": 0.17757956683635712,
      "learning_rate": 2.1146953405017924e-06,
      "loss": 0.0048,
      "step": 561
    },
    {
      "epoch": 3.6242960579243766,
      "grad_norm": 0.3530768156051636,
      "learning_rate": 2.078853046594982e-06,
      "loss": 0.0112,
      "step": 562
    },
    {
      "epoch": 3.6307320997586485,
      "grad_norm": 0.2763892412185669,
      "learning_rate": 2.043010752688172e-06,
      "loss": 0.0202,
      "step": 563
    },
    {
      "epoch": 3.6371681415929205,
      "grad_norm": 1.8607652187347412,
      "learning_rate": 2.0071684587813622e-06,
      "loss": 0.2119,
      "step": 564
    },
    {
      "epoch": 3.6436041834271924,
      "grad_norm": 0.26195579767227173,
      "learning_rate": 1.9713261648745523e-06,
      "loss": 0.0213,
      "step": 565
    },
    {
      "epoch": 3.6500402252614643,
      "grad_norm": 0.3472193479537964,
      "learning_rate": 1.935483870967742e-06,
      "loss": 0.033,
      "step": 566
    },
    {
      "epoch": 3.6564762670957363,
      "grad_norm": 0.24082863330841064,
      "learning_rate": 1.8996415770609319e-06,
      "loss": 0.0194,
      "step": 567
    },
    {
      "epoch": 3.662912308930008,
      "grad_norm": 0.3842553496360779,
      "learning_rate": 1.8637992831541222e-06,
      "loss": 0.0332,
      "step": 568
    },
    {
      "epoch": 3.66934835076428,
      "grad_norm": 0.2582770586013794,
      "learning_rate": 1.827956989247312e-06,
      "loss": 0.0108,
      "step": 569
    },
    {
      "epoch": 3.675784392598552,
      "grad_norm": 0.27031123638153076,
      "learning_rate": 1.792114695340502e-06,
      "loss": 0.0112,
      "step": 570
    },
    {
      "epoch": 3.682220434432824,
      "grad_norm": 0.19125911593437195,
      "learning_rate": 1.7562724014336918e-06,
      "loss": 0.0182,
      "step": 571
    },
    {
      "epoch": 3.688656476267096,
      "grad_norm": 0.17064616084098816,
      "learning_rate": 1.720430107526882e-06,
      "loss": 0.0051,
      "step": 572
    },
    {
      "epoch": 3.695092518101368,
      "grad_norm": 0.3774130642414093,
      "learning_rate": 1.6845878136200718e-06,
      "loss": 0.0896,
      "step": 573
    },
    {
      "epoch": 3.70152855993564,
      "grad_norm": 0.1775728166103363,
      "learning_rate": 1.6487455197132617e-06,
      "loss": 0.0175,
      "step": 574
    },
    {
      "epoch": 3.7079646017699117,
      "grad_norm": 0.3409472405910492,
      "learning_rate": 1.6129032258064516e-06,
      "loss": 0.032,
      "step": 575
    },
    {
      "epoch": 3.7144006436041836,
      "grad_norm": 0.46877896785736084,
      "learning_rate": 1.5770609318996417e-06,
      "loss": 0.0872,
      "step": 576
    },
    {
      "epoch": 3.7208366854384556,
      "grad_norm": 0.4483743906021118,
      "learning_rate": 1.5412186379928318e-06,
      "loss": 0.0762,
      "step": 577
    },
    {
      "epoch": 3.7272727272727275,
      "grad_norm": 0.1798323392868042,
      "learning_rate": 1.5053763440860217e-06,
      "loss": 0.0117,
      "step": 578
    },
    {
      "epoch": 3.7337087691069994,
      "grad_norm": 0.34805288910865784,
      "learning_rate": 1.4695340501792116e-06,
      "loss": 0.0163,
      "step": 579
    },
    {
      "epoch": 3.7401448109412714,
      "grad_norm": 0.35014358162879944,
      "learning_rate": 1.4336917562724014e-06,
      "loss": 0.02,
      "step": 580
    },
    {
      "epoch": 3.7465808527755433,
      "grad_norm": 0.17982198297977448,
      "learning_rate": 1.3978494623655913e-06,
      "loss": 0.0092,
      "step": 581
    },
    {
      "epoch": 3.753016894609815,
      "grad_norm": 0.36781689524650574,
      "learning_rate": 1.3620071684587816e-06,
      "loss": 0.0133,
      "step": 582
    },
    {
      "epoch": 3.7594529364440867,
      "grad_norm": 0.1406601369380951,
      "learning_rate": 1.3261648745519715e-06,
      "loss": 0.0073,
      "step": 583
    },
    {
      "epoch": 3.7658889782783587,
      "grad_norm": 0.14638423919677734,
      "learning_rate": 1.2903225806451614e-06,
      "loss": 0.0045,
      "step": 584
    },
    {
      "epoch": 3.7723250201126306,
      "grad_norm": 0.17987903952598572,
      "learning_rate": 1.2544802867383513e-06,
      "loss": 0.013,
      "step": 585
    },
    {
      "epoch": 3.7787610619469025,
      "grad_norm": 0.47277262806892395,
      "learning_rate": 1.2186379928315414e-06,
      "loss": 0.0183,
      "step": 586
    },
    {
      "epoch": 3.7851971037811745,
      "grad_norm": 0.28884071111679077,
      "learning_rate": 1.1827956989247313e-06,
      "loss": 0.0227,
      "step": 587
    },
    {
      "epoch": 3.7916331456154464,
      "grad_norm": 0.5017927289009094,
      "learning_rate": 1.1469534050179212e-06,
      "loss": 0.0177,
      "step": 588
    },
    {
      "epoch": 3.7980691874497183,
      "grad_norm": 2.5027377605438232,
      "learning_rate": 1.111111111111111e-06,
      "loss": 0.1922,
      "step": 589
    },
    {
      "epoch": 3.8045052292839903,
      "grad_norm": 0.5234145522117615,
      "learning_rate": 1.0752688172043011e-06,
      "loss": 0.0303,
      "step": 590
    },
    {
      "epoch": 3.810941271118262,
      "grad_norm": 0.34689897298812866,
      "learning_rate": 1.039426523297491e-06,
      "loss": 0.0225,
      "step": 591
    },
    {
      "epoch": 3.817377312952534,
      "grad_norm": 0.18197506666183472,
      "learning_rate": 1.0035842293906811e-06,
      "loss": 0.0059,
      "step": 592
    },
    {
      "epoch": 3.823813354786806,
      "grad_norm": 0.1507931500673294,
      "learning_rate": 9.67741935483871e-07,
      "loss": 0.0161,
      "step": 593
    },
    {
      "epoch": 3.830249396621078,
      "grad_norm": 0.6014028787612915,
      "learning_rate": 9.318996415770611e-07,
      "loss": 0.1658,
      "step": 594
    },
    {
      "epoch": 3.83668543845535,
      "grad_norm": 0.3183056116104126,
      "learning_rate": 8.96057347670251e-07,
      "loss": 0.0278,
      "step": 595
    },
    {
      "epoch": 3.843121480289622,
      "grad_norm": 0.6624717116355896,
      "learning_rate": 8.60215053763441e-07,
      "loss": 0.0991,
      "step": 596
    },
    {
      "epoch": 3.849557522123894,
      "grad_norm": 0.43640244007110596,
      "learning_rate": 8.243727598566309e-07,
      "loss": 0.0275,
      "step": 597
    },
    {
      "epoch": 3.8559935639581657,
      "grad_norm": 0.14875271916389465,
      "learning_rate": 7.885304659498208e-07,
      "loss": 0.0087,
      "step": 598
    },
    {
      "epoch": 3.8624296057924377,
      "grad_norm": 0.28664183616638184,
      "learning_rate": 7.526881720430108e-07,
      "loss": 0.0089,
      "step": 599
    },
    {
      "epoch": 3.8688656476267096,
      "grad_norm": 0.4945569336414337,
      "learning_rate": 7.168458781362007e-07,
      "loss": 0.1012,
      "step": 600
    },
    {
      "epoch": 3.8688656476267096,
      "eval_loss": 0.045239128172397614,
      "eval_runtime": 51.4576,
      "eval_samples_per_second": 24.156,
      "eval_steps_per_second": 1.516,
      "step": 600
    },
    {
      "epoch": 3.8753016894609815,
      "grad_norm": 0.36604222655296326,
      "learning_rate": 6.810035842293908e-07,
      "loss": 0.0124,
      "step": 601
    },
    {
      "epoch": 3.8817377312952535,
      "grad_norm": 0.5047851800918579,
      "learning_rate": 6.451612903225807e-07,
      "loss": 0.0781,
      "step": 602
    },
    {
      "epoch": 3.8881737731295254,
      "grad_norm": 0.2554355263710022,
      "learning_rate": 6.093189964157707e-07,
      "loss": 0.0145,
      "step": 603
    },
    {
      "epoch": 3.8946098149637973,
      "grad_norm": 0.8773285746574402,
      "learning_rate": 5.734767025089606e-07,
      "loss": 0.0813,
      "step": 604
    },
    {
      "epoch": 3.9010458567980693,
      "grad_norm": 0.43338334560394287,
      "learning_rate": 5.376344086021506e-07,
      "loss": 0.0782,
      "step": 605
    },
    {
      "epoch": 3.907481898632341,
      "grad_norm": 0.2087218165397644,
      "learning_rate": 5.017921146953406e-07,
      "loss": 0.0186,
      "step": 606
    },
    {
      "epoch": 3.913917940466613,
      "grad_norm": 0.4713188111782074,
      "learning_rate": 4.6594982078853055e-07,
      "loss": 0.0184,
      "step": 607
    },
    {
      "epoch": 3.920353982300885,
      "grad_norm": 0.4873568117618561,
      "learning_rate": 4.301075268817205e-07,
      "loss": 0.0461,
      "step": 608
    },
    {
      "epoch": 3.926790024135157,
      "grad_norm": 0.18693090975284576,
      "learning_rate": 3.942652329749104e-07,
      "loss": 0.0136,
      "step": 609
    },
    {
      "epoch": 3.933226065969429,
      "grad_norm": 0.45981767773628235,
      "learning_rate": 3.5842293906810036e-07,
      "loss": 0.0254,
      "step": 610
    },
    {
      "epoch": 3.939662107803701,
      "grad_norm": 0.2796382009983063,
      "learning_rate": 3.2258064516129035e-07,
      "loss": 0.0118,
      "step": 611
    },
    {
      "epoch": 3.946098149637973,
      "grad_norm": 0.24324718117713928,
      "learning_rate": 2.867383512544803e-07,
      "loss": 0.0197,
      "step": 612
    },
    {
      "epoch": 3.9525341914722447,
      "grad_norm": 0.595201849937439,
      "learning_rate": 2.508960573476703e-07,
      "loss": 0.1586,
      "step": 613
    },
    {
      "epoch": 3.9589702333065167,
      "grad_norm": 0.49937865138053894,
      "learning_rate": 2.1505376344086024e-07,
      "loss": 0.0856,
      "step": 614
    },
    {
      "epoch": 3.965406275140788,
      "grad_norm": 0.4990032911300659,
      "learning_rate": 1.7921146953405018e-07,
      "loss": 0.0135,
      "step": 615
    },
    {
      "epoch": 3.97184231697506,
      "grad_norm": 0.3279082179069519,
      "learning_rate": 1.4336917562724014e-07,
      "loss": 0.0224,
      "step": 616
    },
    {
      "epoch": 3.978278358809332,
      "grad_norm": 0.18537664413452148,
      "learning_rate": 1.0752688172043012e-07,
      "loss": 0.0104,
      "step": 617
    },
    {
      "epoch": 3.984714400643604,
      "grad_norm": 0.4141295552253723,
      "learning_rate": 7.168458781362007e-08,
      "loss": 0.0226,
      "step": 618
    },
    {
      "epoch": 3.991150442477876,
      "grad_norm": 0.4989748001098633,
      "learning_rate": 3.5842293906810036e-08,
      "loss": 0.0824,
      "step": 619
    },
    {
      "epoch": 3.997586484312148,
      "grad_norm": 0.8574862480163574,
      "learning_rate": 0.0,
      "loss": 0.1301,
      "step": 620
    },
    {
      "epoch": 3.997586484312148,
      "step": 620,
      "total_flos": 4.3243513483729306e+17,
      "train_loss": 0.17207530220677594,
      "train_runtime": 2662.8461,
      "train_samples_per_second": 7.464,
      "train_steps_per_second": 0.233
    }
  ],
  "logging_steps": 1,
  "max_steps": 620,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.3243513483729306e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
